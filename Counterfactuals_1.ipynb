{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This file is used to calculate the coutnerfactual review differences based on the new descriptions."
      ],
      "metadata": {
        "id": "F9WXjbyyLT72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install miceforest\n",
        "!pip install sentence_transformers\n",
        "!pip install accelerate\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fZzzBVB9LS9Z",
        "outputId": "1017ff8e-9aba-4cec-daf5-4472f966d7e7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.33.1-py3-none-any.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.15.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.16.4-py3-none-any.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.16.4 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.33.1\n",
            "Collecting miceforest\n",
            "  Downloading miceforest-5.6.3-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/58.0 kB\u001b[0m \u001b[31m593.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: lightgbm>=3.3.1 in /usr/local/lib/python3.10/dist-packages (from miceforest) (4.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from miceforest) (1.23.5)\n",
            "Collecting blosc (from miceforest)\n",
            "  Downloading blosc-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dill (from miceforest)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm>=3.3.1->miceforest) (1.10.1)\n",
            "Installing collected packages: dill, blosc, miceforest\n",
            "Successfully installed blosc-1.11.1 dill-0.3.7 miceforest-5.6.3\n",
            "Collecting sentence_transformers\n",
            "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.33.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.1)\n",
            "Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.0.1+cu118)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.15.2+cu118)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.23.5)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.10.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (3.8.1)\n",
            "Collecting sentencepiece (from sentence_transformers)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.16.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.7.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence_transformers) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence_transformers) (16.0.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.3.3)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence_transformers) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
            "Building wheels for collected packages: sentence_transformers\n",
            "  Building wheel for sentence_transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence_transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125923 sha256=b53d0f4fc6b99e244f56db7e59dc2c7f6219cbcb5fd363ca19396cc3ba8e76cf\n",
            "  Stored in directory: /root/.cache/pip/wheels/62/f2/10/1e606fd5f02395388f74e7462910fe851042f97238cbbd902f\n",
            "Successfully built sentence_transformers\n",
            "Installing collected packages: sentencepiece, sentence_transformers\n",
            "Successfully installed sentence_transformers-2.2.2 sentencepiece-0.1.99\n",
            "Collecting accelerate\n",
            "  Downloading accelerate-0.22.0-py3-none-any.whl (251 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/251.2 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (3.27.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.10.0->accelerate) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Installing collected packages: accelerate\n",
            "Successfully installed accelerate-0.22.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "k6nTNMeXAqqE"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.metrics import classification_report\n",
        "import json\n",
        "import cv2\n",
        "from tqdm.auto import tqdm\n",
        "from accelerate import Accelerator\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### functions ###\n",
        "\n",
        "import random\n",
        "\n",
        "def permutation_test(list_1, list_2, num_permutations):\n",
        "\n",
        "  counter = 0\n",
        "\n",
        "  real_diff = np.mean(list_1 - list_2)\n",
        "\n",
        "  for i in range(num_permutations):\n",
        "\n",
        "    added_list = list(list_1) +(list(list_2))\n",
        "\n",
        "    # shufflig in place: https://stackoverflow.com/questions/47516428/cant-get-random-shuffle-to-work-python-random-shuffle\n",
        "    random.shuffle(added_list)\n",
        "\n",
        "    cut_off = 0.5*np.floor(len(added_list))\n",
        "    first_part = added_list[:int(cut_off)]\n",
        "    second_part = added_list[int(cut_off):]\n",
        "\n",
        "    if np.abs(np.mean(first_part)-np.mean(second_part)) > real_diff:\n",
        "      counter += 1\n",
        "\n",
        "    #print(i)\n",
        "\n",
        "  emp_p_val =  counter / num_permutations\n",
        "\n",
        "  return emp_p_val\n",
        "\n",
        "\n",
        "## should be runing for around 10-15 minutes on V100 GPU\n",
        "\n",
        "def get_counterfactuals(model, dl, cont: True):\n",
        "\n",
        "    \"\"\" This function computes the couterfactuals given the generated names\n",
        "        cont = True if continuous model, if false categorical model is expected\n",
        "    \"\"\"\n",
        "\n",
        "    device = \"cuda\"\n",
        "\n",
        "    ids = []\n",
        "    preds_ = []\n",
        "    Ys = []\n",
        "\n",
        "    count_idx = 1\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for batch in dl:\n",
        "\n",
        "        #print(count_idx/len(dl))\n",
        "        count_idx += 1\n",
        "\n",
        "        img = batch[0].to(device)\n",
        "        name = torch.tensor(batch[1]).to(device)\n",
        "        joint_des = torch.tensor(batch[2]).to(device)\n",
        "        X = batch[3].to(device)\n",
        "        if cont == True:\n",
        "          Y = torch.tensor(batch[5])\n",
        "        else:\n",
        "          Y = [int(i+1) for i in np.argmax(batch[2], axis = 1)]\n",
        "\n",
        "        pred = model(img, name, joint_des, X)\n",
        "\n",
        "        ids.extend(batch[6])\n",
        "\n",
        "        if cont == True:\n",
        "          preds_.extend(pred.cpu().numpy() )\n",
        "        else:\n",
        "          cat_pred = [i+1 for i in np.argmax(pred.cpu().numpy()[0], axis = 1)]\n",
        "          preds_.extend(cat_pred)\n",
        "\n",
        "        if cont == True:\n",
        "          Ys.extend(Y.cpu().numpy() )\n",
        "        else:\n",
        "          Ys.extend(Y)\n",
        "\n",
        "\n",
        "    return Ys, preds_, ids\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Simple_Dataset(Dataset):\n",
        "\n",
        "    ''' This class transforms the input data to a useable dataset, which can be passed\n",
        "    to PyTorch's dataloader class in a very generic fashion. The collate function needs to\n",
        "    actually define the variables here!'''\n",
        "\n",
        "    def __init__(self, df):\n",
        "        # also defining default value #\n",
        "\n",
        "        # data as Pytorch tensors via the collate batches function\n",
        "        self.data = np.array(df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return (self.data[idx])\n",
        "\n",
        "    def __len__(self):\n",
        "        return(self.data.shape[0])\n"
      ],
      "metadata": {
        "id": "Ai09rTsRo-5y"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# connecting to drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOELE9frLprs",
        "outputId": "becc948e-c625-4196-d2e5-bb6576f921b4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading in the prepared DF for the dicriminator models and the DF containing the generated titles"
      ],
      "metadata": {
        "id": "IVBmDk6fzCGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## reading in tabuar data\n",
        "\n",
        "\n",
        "airbnb_london_filtered_images_imp_var = pd.read_csv(\"/content/gdrive/My Drive/Thesis/London_Data/airbnb_london_filtered_images_counterfactual_prep.csv\")\n"
      ],
      "metadata": {
        "id": "hFR71WyUhrPg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred_disc_2_cont_real_name = pd.read_csv(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/pred_disc_2_cont_real_name_all_2.csv\")\n"
      ],
      "metadata": {
        "id": "m9NPi3fy3SYj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "I shall now check for a bias in the coutnerfactuals (as compared to the true titles) for proxy classes 1 & 2.\n",
        "Note that even if the means are not different (statistically no bias), a bias towards the mean or too high/too small variances might be present which alter the results to be calculated below.\n",
        "Thus, using the coutnerfactuals based on the true titles makes more sense than simply using the true review difference counts."
      ],
      "metadata": {
        "id": "vP9HodAoxhUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred_disc_2_cont_real_name_proxy = pd.merge(pred_disc_2_cont_real_name, airbnb_london_filtered_images_imp_var[[\"id\", \"proxy\"]], how = \"inner\", on = \"id\")\n",
        "np.mean(pred_disc_2_cont_real_name_proxy.pred[pred_disc_2_cont_real_name_proxy.proxy != 3]    -   pred_disc_2_cont_real_name_proxy.Y[pred_disc_2_cont_real_name_proxy.proxy != 3])\n",
        "\n",
        "## pred is slightly lower than true value!\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYNuXiPyyBO8",
        "outputId": "27bba88e-c1d7-454f-9316-3fe0c5c86674"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.030215809788416138"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gen_titles_summ_models = pd.read_csv(\"/content/gdrive/My Drive/Thesis/London_Data/gen_titles_summ_models.csv\")"
      ],
      "metadata": {
        "id": "AURRlNSww4Bk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_titles_summ_models.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "hmFMEQ4rZ3mt",
        "outputId": "a7fb72df-2665-4c78-b32c-5c8d0ecc57e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      id                    gen_titles_distilbart  \\\n",
              "0  13913   Bright Double Bedroom in Finsbury Park   \n",
              "1  17402       Superb 3-bed 2bath in Fitzrovia W1   \n",
              "2  25123        Lovely double room in clean house   \n",
              "3  36299  3 Bed House near the river, Kew Gardens   \n",
              "4  39387      Private bedsit room in quiet street   \n",
              "\n",
              "                                 gen_titles_bart  \\\n",
              "0  Lovely Double Bedroom in Finsbury Park London   \n",
              "1               Superb Fitzrovia 3-bed 2-bath w/   \n",
              "2            Room to let up to 6 months or more.   \n",
              "3      3 Bed House by Thames River, Kew Gardens,   \n",
              "4                      BEDSIT ROOM IN Euston W14   \n",
              "\n",
              "                              gen_titles_pegasus  \n",
              "0         Lovely double bedroom in Finsbury Park  \n",
              "1       Modern Fitzrovia Apartment with Elevator  \n",
              "2             Large double room in Golders Green  \n",
              "3  3 Bed House with garden close to Thames river  \n",
              "4           Private lockable room in bright flat  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-7d600092-7102-4808-9587-50b7134a76df\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gen_titles_distilbart</th>\n",
              "      <th>gen_titles_bart</th>\n",
              "      <th>gen_titles_pegasus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13913</td>\n",
              "      <td>Bright Double Bedroom in Finsbury Park</td>\n",
              "      <td>Lovely Double Bedroom in Finsbury Park London</td>\n",
              "      <td>Lovely double bedroom in Finsbury Park</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>17402</td>\n",
              "      <td>Superb 3-bed 2bath in Fitzrovia W1</td>\n",
              "      <td>Superb Fitzrovia 3-bed 2-bath w/</td>\n",
              "      <td>Modern Fitzrovia Apartment with Elevator</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>25123</td>\n",
              "      <td>Lovely double room in clean house</td>\n",
              "      <td>Room to let up to 6 months or more.</td>\n",
              "      <td>Large double room in Golders Green</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>36299</td>\n",
              "      <td>3 Bed House near the river, Kew Gardens</td>\n",
              "      <td>3 Bed House by Thames River, Kew Gardens,</td>\n",
              "      <td>3 Bed House with garden close to Thames river</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>39387</td>\n",
              "      <td>Private bedsit room in quiet street</td>\n",
              "      <td>BEDSIT ROOM IN Euston W14</td>\n",
              "      <td>Private lockable room in bright flat</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7d600092-7102-4808-9587-50b7134a76df')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-e648f686-6abe-421f-b184-0cc1991f83f6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e648f686-6abe-421f-b184-0cc1991f83f6')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-e648f686-6abe-421f-b184-0cc1991f83f6 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7d600092-7102-4808-9587-50b7134a76df button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7d600092-7102-4808-9587-50b7134a76df');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## merging both\n",
        "\n",
        "airbnb_london_filtered_images_imp_var_titles = pd.merge(airbnb_london_filtered_images_imp_var, gen_titles_summ_models, how = \"left\", on  = \"id\" )"
      ],
      "metadata": {
        "id": "MsrP9QKDzN1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "airbnb_london_filtered_images_imp_var_titles.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 751
        },
        "id": "ZnL6TNiDzXyP",
        "outputId": "384cd0c1-eba5-4b64-a1f5-25c5451f05f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   number_of_reviews_ltm  room_type  reviews_per_month  has_amenity_Iron  \\\n",
              "0                    5.0          1               0.18                 1   \n",
              "1                    7.0          0               0.36                 1   \n",
              "2                    0.0          1               0.87                 1   \n",
              "3                   13.0          0               0.65                 1   \n",
              "4                    0.0          1               0.10                 1   \n",
              "\n",
              "   Tower Hamlets  price  minimum_nights  has_amenity_Cooking basics  Enfield  \\\n",
              "0              0   49.0             1.0                           1        0   \n",
              "1              0  379.0             4.0                           1        0   \n",
              "2              0   29.0            10.0                           0        0   \n",
              "3              0  195.0             3.0                           1        0   \n",
              "4              0   42.0             5.0                           1        0   \n",
              "\n",
              "   Kensington and Chelsea  ...  has_amenity_Essentials  has_amenity_Dryer  \\\n",
              "0                       0  ...                       1                  1   \n",
              "1                       0  ...                       1                  1   \n",
              "2                       0  ...                       1                  0   \n",
              "3                       0  ...                       1                  1   \n",
              "4                       0  ...                       1                  1   \n",
              "\n",
              "      id                                      name  \\\n",
              "0  13913       Holiday London DB Room Let-on going   \n",
              "1  17402     Superb 3-Bed/2 Bath & Wifi: Trendy W1   \n",
              "2  25123         Clean big Room in London (Room 1)   \n",
              "3  36299       Kew Gardens 3BR house in cul-de-sac   \n",
              "4  39387  Stylish bedsit in Notting Hill ish flat.   \n",
              "\n",
              "                                   joint_description  proxy  review_diff  \\\n",
              "0  My bright double bedroom with a large window h...      3         15.0   \n",
              "1  You'll have a wonderful stay in this superb mo...      3          5.0   \n",
              "2  Big room with double bed clean sheets clean to...      1          0.0   \n",
              "3  3 Bed House with garden close to Thames river ...      3          7.0   \n",
              "4  Private lockable bedsit room available within ...      1          0.0   \n",
              "\n",
              "                     gen_titles_distilbart  \\\n",
              "0   Bright Double Bedroom in Finsbury Park   \n",
              "1       Superb 3-bed 2bath in Fitzrovia W1   \n",
              "2        Lovely double room in clean house   \n",
              "3  3 Bed House near the river, Kew Gardens   \n",
              "4      Private bedsit room in quiet street   \n",
              "\n",
              "                                 gen_titles_bart  \\\n",
              "0  Lovely Double Bedroom in Finsbury Park London   \n",
              "1               Superb Fitzrovia 3-bed 2-bath w/   \n",
              "2            Room to let up to 6 months or more.   \n",
              "3      3 Bed House by Thames River, Kew Gardens,   \n",
              "4                      BEDSIT ROOM IN Euston W14   \n",
              "\n",
              "                              gen_titles_pegasus  \n",
              "0         Lovely double bedroom in Finsbury Park  \n",
              "1       Modern Fitzrovia Apartment with Elevator  \n",
              "2             Large double room in Golders Green  \n",
              "3  3 Bed House with garden close to Thames river  \n",
              "4           Private lockable room in bright flat  \n",
              "\n",
              "[5 rows x 70 columns]"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-b0f661d4-bdcb-4319-a7ba-f26aad4b5c3d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>number_of_reviews_ltm</th>\n",
              "      <th>room_type</th>\n",
              "      <th>reviews_per_month</th>\n",
              "      <th>has_amenity_Iron</th>\n",
              "      <th>Tower Hamlets</th>\n",
              "      <th>price</th>\n",
              "      <th>minimum_nights</th>\n",
              "      <th>has_amenity_Cooking basics</th>\n",
              "      <th>Enfield</th>\n",
              "      <th>Kensington and Chelsea</th>\n",
              "      <th>...</th>\n",
              "      <th>has_amenity_Essentials</th>\n",
              "      <th>has_amenity_Dryer</th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>joint_description</th>\n",
              "      <th>proxy</th>\n",
              "      <th>review_diff</th>\n",
              "      <th>gen_titles_distilbart</th>\n",
              "      <th>gen_titles_bart</th>\n",
              "      <th>gen_titles_pegasus</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.18</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>49.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>13913</td>\n",
              "      <td>Holiday London DB Room Let-on going</td>\n",
              "      <td>My bright double bedroom with a large window h...</td>\n",
              "      <td>3</td>\n",
              "      <td>15.0</td>\n",
              "      <td>Bright Double Bedroom in Finsbury Park</td>\n",
              "      <td>Lovely Double Bedroom in Finsbury Park London</td>\n",
              "      <td>Lovely double bedroom in Finsbury Park</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.36</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>379.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>17402</td>\n",
              "      <td>Superb 3-Bed/2 Bath &amp; Wifi: Trendy W1</td>\n",
              "      <td>You'll have a wonderful stay in this superb mo...</td>\n",
              "      <td>3</td>\n",
              "      <td>5.0</td>\n",
              "      <td>Superb 3-bed 2bath in Fitzrovia W1</td>\n",
              "      <td>Superb Fitzrovia 3-bed 2-bath w/</td>\n",
              "      <td>Modern Fitzrovia Apartment with Elevator</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.87</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>29.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>25123</td>\n",
              "      <td>Clean big Room in London (Room 1)</td>\n",
              "      <td>Big room with double bed clean sheets clean to...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Lovely double room in clean house</td>\n",
              "      <td>Room to let up to 6 months or more.</td>\n",
              "      <td>Large double room in Golders Green</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.65</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>195.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>36299</td>\n",
              "      <td>Kew Gardens 3BR house in cul-de-sac</td>\n",
              "      <td>3 Bed House with garden close to Thames river ...</td>\n",
              "      <td>3</td>\n",
              "      <td>7.0</td>\n",
              "      <td>3 Bed House near the river, Kew Gardens</td>\n",
              "      <td>3 Bed House by Thames River, Kew Gardens,</td>\n",
              "      <td>3 Bed House with garden close to Thames river</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.10</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>39387</td>\n",
              "      <td>Stylish bedsit in Notting Hill ish flat.</td>\n",
              "      <td>Private lockable bedsit room available within ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Private bedsit room in quiet street</td>\n",
              "      <td>BEDSIT ROOM IN Euston W14</td>\n",
              "      <td>Private lockable room in bright flat</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 70 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b0f661d4-bdcb-4319-a7ba-f26aad4b5c3d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-9af99b05-c839-47dd-a64c-1e43b190b3d5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9af99b05-c839-47dd-a64c-1e43b190b3d5')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-9af99b05-c839-47dd-a64c-1e43b190b3d5 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b0f661d4-bdcb-4319-a7ba-f26aad4b5c3d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b0f661d4-bdcb-4319-a7ba-f26aad4b5c3d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Embedding generated titles into JSON-based vector database\n",
        "\n",
        "Does not need to be repeated, hence commented out!"
      ],
      "metadata": {
        "id": "OdrbPGL1eJYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "### loading in retrained SBERT\n",
        "#model_save_name = 'sbert_tuned.pth'\n",
        "#path =\"/content/gdrive/My Drive/Thesis/Models/{}\".format(model_save_name)\n",
        "\n",
        "#text_model = torch.load(path)\n",
        "#text_model = text_model.to(\"cuda\")\n"
      ],
      "metadata": {
        "id": "beBIuz9seJYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### For BART"
      ],
      "metadata": {
        "id": "Ngy1McmGdHng"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dict_titles_bart = {}\n"
      ],
      "metadata": {
        "id": "SWtX82SydHnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for idx in range(gen_titles_summ_models.shape[0]):\n",
        "\n",
        "#  print(idx/gen_titles_summ_models.shape[0])\n",
        "\n",
        "#  id = gen_titles_summ_models.id[idx]\n",
        "\n",
        "#  enc1 = text_model.encode(gen_titles_summ_models.gen_titles_bart[idx])\n",
        "#  enc = enc1.tolist()\n",
        "\n",
        "#  dict_titles_bart[int(id)] = enc\n",
        "\n",
        "#  if idx % 200 == 0:\n",
        "#    x = json.dumps(dict_titles_bart)\n",
        "#    with open(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/json_bart_encoded.json\", 'w') as f:\n",
        "#      f.write(x)\n",
        "\n",
        "#x = json.dumps(dict_titles_bart)\n",
        "#with open(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/json_bart_encoded.json\", 'w') as f:\n",
        "#  f.write(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "2QUQVu-FdHnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### For DistilBART"
      ],
      "metadata": {
        "id": "K-sBO5OleJYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dict_titles_distilbart = {}\n"
      ],
      "metadata": {
        "id": "btDmPZL_eJYz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for idx in range(gen_titles_summ_models.shape[0]):\n",
        "\n",
        "#  print(idx/gen_titles_summ_models.shape[0])\n",
        "\n",
        "#  id = gen_titles_summ_models.id[idx]\n",
        "\n",
        "#  enc1 = text_model.encode(gen_titles_summ_models.gen_titles_distilbart[idx])\n",
        "#  enc = enc1.tolist()\n",
        "\n",
        "#  dict_titles_distilbart[int(id)] = enc\n",
        "\n",
        "#  if idx % 200 == 0:\n",
        "#    x = json.dumps(dict_titles_distilbart)\n",
        "#    with open(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/json_distilbart_encoded.json\", 'w') as f:\n",
        "#      f.write(x)\n",
        "\n",
        "#x = json.dumps(dict_titles_distilbart)\n",
        "#with open(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/json_distilbart_encoded.json\", 'w') as f:\n",
        "#  f.write(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "eDiEd9m6eJY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### For PEGASUS"
      ],
      "metadata": {
        "id": "C6gOPcRueWoj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#dict_titles_pegasus = {}\n"
      ],
      "metadata": {
        "id": "okEryVN2eWox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for idx in range(gen_titles_summ_models.shape[0]):\n",
        "\n",
        "#  print(idx/gen_titles_summ_models.shape[0])\n",
        "\n",
        "#  id = gen_titles_summ_models.id[idx]\n",
        "\n",
        "#  enc1 = text_model.encode(gen_titles_summ_models.gen_titles_pegasus[idx])\n",
        "#  enc = enc1.tolist()\n",
        "\n",
        "#  dict_titles_pegasus[int(id)] = enc\n",
        "\n",
        "#  if idx % 200 == 0:\n",
        "#    x = json.dumps(dict_titles_pegasus)\n",
        "#    with open(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/json_pegasus_encoded.json\", 'w') as f:\n",
        "#     f.write(x)\n",
        "\n",
        "#x = json.dumps(dict_titles_pegasus)\n",
        "#with open(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/json_pegasus_encoded.json\", 'w') as f:\n",
        "#  f.write(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "TBGGAICKeWo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Llama-Genenration 1"
      ],
      "metadata": {
        "id": "HIq9jpOm9yEx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### For Llama (Low-Rank Adaptation)"
      ],
      "metadata": {
        "id": "mfHdLK7Qe2qN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#llama_lora = pd.read_csv(\"/content/gdrive/My Drive/Thesis/loss_data/gen_titles_llama.csv\")\n",
        "#dict_titles_llama_lora = {}\n"
      ],
      "metadata": {
        "id": "nEUX3dbifH3J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for idx in range(llama_lora.shape[0]):\n",
        "\n",
        "#  print(idx/llama_lora.shape[0])\n",
        "\n",
        "#  id = llama_lora.id[idx]\n",
        "\n",
        "#  enc1 = text_model.encode(llama_lora.gen_title[idx])\n",
        "#  enc = enc1.tolist()\n",
        "\n",
        "#  dict_titles_llama_lora[int(id)] = enc\n",
        "\n",
        "#  if idx % 200 == 0:\n",
        "#    x = json.dumps(dict_titles_llama_lora)\n",
        "#    with open(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/json_llama_lora_encoded.json\", 'w') as f:\n",
        "#      f.write(x)\n",
        "\n",
        "#x = json.dumps(dict_titles_llama_lora)\n",
        "#with open(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/json_llama_lora_encoded.json\", 'w') as f:\n",
        "#  f.write(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "4Bdxriv_e2qb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### For Llama-Adapter"
      ],
      "metadata": {
        "id": "8vr7-RHXN1Th"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#llama_adapter = pd.read_csv(\"/content/gdrive/My Drive/Thesis/loss_data/gen_titles_llama_adapter.csv\")\n",
        "#dict_titles_llama_adapter = {}\n"
      ],
      "metadata": {
        "id": "8WVMKOZhN1Tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for idx in range(llama_adapter.shape[0]):\n",
        "\n",
        "#  print(idx/llama_adapter.shape[0])\n",
        "\n",
        "#  id = llama_adapter.id[idx]\n",
        "\n",
        "#  enc1 = text_model.encode(llama_adapter.gen_titles[idx])\n",
        "#  enc = enc1.tolist()\n",
        "\n",
        "#  dict_titles_llama_adapter[int(id)] = enc\n",
        "\n",
        "#  if idx % 200 == 0:\n",
        "#    x = json.dumps(dict_titles_llama_adapter)\n",
        "#    with open(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/json_llama_adapter_encoded.json\", 'w') as f:\n",
        "#      f.write(x)\n",
        "\n",
        "#x = json.dumps(dict_titles_llama_adapter)\n",
        "#with open(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/json_llama_adapter_encoded.json\", 'w') as f:\n",
        "#  f.write(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "ffjqqvbPN1Tr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### For Llama - no PEFT"
      ],
      "metadata": {
        "id": "PLywgtAfcpUE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#llama_no_peft = pd.read_csv(\"/content/gdrive/My Drive/Thesis/loss_data/gen_titles_llama_no_peft.csv\")\n",
        "#dict_titles_llama_no_peft = {}\n"
      ],
      "metadata": {
        "id": "O0tTqWIIcpUK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for idx in range(llama_no_peft.shape[0]):\n",
        "\n",
        "#  print(idx/llama_no_peft.shape[0])\n",
        "\n",
        "#  id = llama_no_peft.id[idx]\n",
        "\n",
        "#  enc1 = text_model.encode(llama_no_peft.gen_title[idx])\n",
        "#  enc = enc1.tolist()\n",
        "\n",
        "#  dict_titles_llama_no_peft[int(id)] = enc\n",
        "\n",
        "#  if idx % 200 == 0:\n",
        "#    x = json.dumps(dict_titles_llama_no_peft)\n",
        "#    with open(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/json_llama_no_peft_encoded.json\", 'w') as f:\n",
        "#      f.write(x)\n",
        "\n",
        "#x = json.dumps(dict_titles_llama_no_peft)\n",
        "#with open(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/json_llama_no_peft_encoded.json\", 'w') as f:\n",
        "#  f.write(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "Dig1XUXmcpUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Llama-Genenration 2"
      ],
      "metadata": {
        "id": "V0RQPdoF-ZUt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### For Llama (Low-Rank Adaptation)"
      ],
      "metadata": {
        "id": "Y9JnQ4pJ-ZU8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#llama_lora_2 = pd.read_csv(\"/content/gdrive/My Drive/Thesis/loss_data/gen_titles_llama_v2.csv\")\n",
        "#dict_titles_llama_lora_2 = {}\n"
      ],
      "metadata": {
        "id": "hoXRXcUK-ZU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for idx in range(llama_lora_2.shape[0]):\n",
        "\n",
        "#  print(idx/llama_lora_2.shape[0])\n",
        "\n",
        "#  id = llama_lora_2.id[idx]\n",
        "\n",
        "#  enc1 = text_model.encode(llama_lora_2.gen_title[idx])\n",
        "#  enc = enc1.tolist()\n",
        "\n",
        "#  dict_titles_llama_lora_2[int(id)] = enc\n",
        "\n",
        "#  if idx % 200 == 0:\n",
        "#    x = json.dumps(dict_titles_llama_lora_2)\n",
        "#    with open(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/json_llama_lora_encoded_2.json\", 'w') as f:\n",
        "#      f.write(x)\n",
        "\n",
        "#x = json.dumps(dict_titles_llama_lora_2)\n",
        "#with open(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/json_llama_lora_encoded_2.json\", 'w') as f:\n",
        "#  f.write(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "arhwhlXy-ZVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### For Llama-Adapter"
      ],
      "metadata": {
        "id": "DGcEpHwP-ZVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#llama_adapter_2 = pd.read_csv(\"/content/gdrive/My Drive/Thesis/loss_data/gen_titles_llama_adapter_v2.csv\")\n",
        "#dict_titles_llama_adapter_2 = {}\n"
      ],
      "metadata": {
        "id": "yM-QPmIZ-ZVP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for idx in range(llama_adapter_2.shape[0]):\n",
        "\n",
        "#  print(idx/llama_adapter_2.shape[0])\n",
        "\n",
        "#  id = llama_adapter_2.id[idx]\n",
        "\n",
        "#  enc1 = text_model.encode(llama_adapter_2.gen_titles[idx])\n",
        "#  enc = enc1.tolist()\n",
        "\n",
        "#  dict_titles_llama_adapter_2[int(id)] = enc\n",
        "\n",
        "#  if idx % 200 == 0:\n",
        "#    x = json.dumps(dict_titles_llama_adapter_2)\n",
        "#    with open(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/json_llama_adapter_encoded_2.json\", 'w') as f:\n",
        "#      f.write(x)\n",
        "\n",
        "#x = json.dumps(dict_titles_llama_adapter_2)\n",
        "#with open(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/json_llama_adapter_encoded_2.json\", 'w') as f:\n",
        "#  f.write(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "4x8xGkHM-ZVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### For Llama - no PEFT"
      ],
      "metadata": {
        "id": "FxoByQ_N-ZVd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#llama_no_peft_2 = pd.read_csv(\"/content/gdrive/My Drive/Thesis/loss_data/gen_titles_llama_no_peft_v2.csv\")\n",
        "#dict_titles_llama_no_peft_2 = {}\n"
      ],
      "metadata": {
        "id": "nAnBNGk3-ZVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for idx in range(llama_no_peft_2.shape[0]):\n",
        "\n",
        "#  print(idx/llama_no_peft_2.shape[0])\n",
        "\n",
        "#  id = llama_no_peft_2.id[idx]\n",
        "\n",
        "#  enc1 = text_model.encode(llama_no_peft_2.gen_title[idx])\n",
        "#  enc = enc1.tolist()\n",
        "\n",
        "#  dict_titles_llama_no_peft_2[int(id)] = enc\n",
        "\n",
        "#  if idx % 200 == 0:\n",
        "#    x = json.dumps(dict_titles_llama_no_peft_2)\n",
        "#    with open(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/json_llama_no_peft_encoded_2.json\", 'w') as f:\n",
        "#      f.write(x)\n",
        "\n",
        "#x = json.dumps(dict_titles_llama_no_peft_2)\n",
        "#with open(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/json_llama_no_peft_encoded_2.json\", 'w') as f:\n",
        "#  f.write(x)\n",
        "\n"
      ],
      "metadata": {
        "id": "uhgm50cM-ZVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading in important stuff\n",
        "\n",
        "Including the encoded names (the ones generated with the code just above) and encoded true names, descriptions and images\n"
      ],
      "metadata": {
        "id": "A7PJeesOS85t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# reading in json vector data\n",
        "# sometimes needs to be executed twice\n",
        "\n",
        "import json\n",
        "\n",
        "\n",
        "with open(\"/content/gdrive/My Drive/Thesis/London_Data/json_names.json\") as json_data: ## not really needed here\n",
        "    dict_names = json.load(json_data)\n",
        "\n",
        "with open(\"/content/gdrive/My Drive/Thesis/London_Data/json_des.json\") as json_data:\n",
        "    dict_des = json.load(json_data)\n",
        "\n",
        "with open(\"/content/gdrive/My Drive/Thesis/Image_data/json_images.json\") as json_data:\n",
        "    dict_images = json.load(json_data)\n"
      ],
      "metadata": {
        "id": "cuB8OheapVgZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/json_distilbart_encoded.json\") as json_data:\n",
        "  dict_titles_distilbart = json.load(json_data)\n",
        "\n",
        "with open(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/json_bart_encoded.json\") as json_data:\n",
        "  dict_titles_bart = json.load(json_data)\n",
        "\n",
        "\n",
        "with open(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/json_pegasus_encoded.json\") as json_data:\n",
        "  dict_titles_pegasus = json.load(json_data)\n",
        "\n",
        "with open(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/json_llama_lora_encoded.json\") as json_data:\n",
        "  dict_titles_llama_lora = json.load(json_data)\n",
        "\n",
        "with open(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/json_llama_adapter_encoded.json\") as json_data:\n",
        "  dict_titles_llama_adapter = json.load(json_data)\n",
        "\n",
        "with open(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/json_llama_no_peft_encoded.json\") as json_data:\n",
        "  dict_titles_llama_no_peft = json.load(json_data)"
      ],
      "metadata": {
        "id": "Ahf23c1Vnv8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/json_llama_lora_encoded_2.json\") as json_data:\n",
        "  dict_titles_llama_lora_2 = json.load(json_data)\n",
        "\n",
        "with open(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/json_llama_adapter_encoded_2.json\") as json_data:\n",
        "  dict_titles_llama_adapter_2 = json.load(json_data)\n",
        "\n",
        "with open(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/json_llama_no_peft_encoded_2.json\") as json_data:\n",
        "  dict_titles_llama_no_peft_2 = json.load(json_data)"
      ],
      "metadata": {
        "id": "sBrnq-PtACBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "\n",
        "hidden_dim_1 = 60\n",
        "hidden_dim_2 = 60\n",
        "hidden_dim_3 = 50\n",
        "hidden_dim_4 = 20\n",
        "\n",
        "output_dim = 1\n",
        "\n",
        "\n",
        "## name, des / text model\n",
        "\n",
        "\n",
        "class NeuralNetwork2(nn.Module): ## without extractor\n",
        "    def __init__(self, tab_input_dim, final_output_dim_visual , final_output_dim_text_name, final_output_dim_text_des, hidden_dim_1, hidden_dim_2, hidden_dim_3, hidden_dim_4, output_dim):\n",
        "        super(NeuralNetwork2, self).__init__()\n",
        "\n",
        "\n",
        "        # layers build on top of visual model before concatination\n",
        "        self.visual_add_layer_1 = nn.Linear(768, 100)\n",
        "        self.visual_add_layer_2 = nn.Linear(100, 100)\n",
        "        self.visual_add_layer_3 = nn.Linear(100, 50)\n",
        "        self.visual_add_layer_4 = nn.Linear(50, final_output_dim_visual)\n",
        "\n",
        "        # Layers added after Name/Title\n",
        "        self.name_added_layer_1 = nn.Linear(768, 100)\n",
        "        self.name_added_layer_2 = nn.Linear(100, 100)\n",
        "        ### dropout ##\n",
        "        self.name_added_layer_3 = nn.Linear(100, 50)\n",
        "        self.name_added_layer_4 = nn.Linear(50, final_output_dim_text_name)\n",
        "\n",
        "        # Layers added after Description\n",
        "        self.des_added_layer_1 = nn.Linear(768, 100)\n",
        "        self.des_added_layer_2 = nn.Linear(100, 100)\n",
        "        ### dropout ##\n",
        "        self.des_added_layer_3 = nn.Linear(100, 50)\n",
        "        self.des_added_layer_4 = nn.Linear(50, final_output_dim_text_des)\n",
        "\n",
        "\n",
        "        ### Layers added after Joint Description ###\n",
        "\n",
        "        # dimension after concat operation\n",
        "        self.concat_dim = tab_input_dim + final_output_dim_visual + final_output_dim_text_name + final_output_dim_text_des\n",
        "\n",
        "        # layers processing input after concatination\n",
        "        self.layer_1 = nn.Linear(self.concat_dim, hidden_dim_1)\n",
        "        self.layer_2 = nn.Linear(hidden_dim_1, hidden_dim_2)\n",
        "        self.layer_3 = nn.Linear(hidden_dim_2, hidden_dim_3)\n",
        "        self.layer_4 = nn.Linear(hidden_dim_3, hidden_dim_4)\n",
        "        self.layer_5 = nn.Linear(hidden_dim_4, output_dim)\n",
        "\n",
        "        # Regu features\n",
        "        self.dropout = nn.Dropout(0.03)\n",
        "        self.batch_norm_1 = nn.BatchNorm1d(hidden_dim_2) # 1-dim batch norm with covariance-shift params activated\n",
        "        self.batch_norm_2 = nn.BatchNorm1d(hidden_dim_3)\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, img_encoded, name_encoded, des_encoded, X):  ## name, des\n",
        "\n",
        "        ## firstly processing outputs of visual and textual model ##\n",
        "\n",
        "        # visual model\n",
        "        output_img = torch.nn.functional.tanh(self.visual_add_layer_1(img_encoded))\n",
        "        output_img = self.dropout(output_img)\n",
        "        output_img = torch.nn.functional.tanh(self.visual_add_layer_2(output_img))\n",
        "        output_img = torch.nn.functional.tanh(self.visual_add_layer_3(output_img))\n",
        "        final_output_img = torch.nn.functional.tanh(self.visual_add_layer_4(output_img))\n",
        "\n",
        "        # textual - description\n",
        "        encoded_des = torch.tensor(des_encoded)\n",
        "        encoded_des = torch.nn.functional.tanh(self.des_added_layer_1(encoded_des))\n",
        "        encoded_des = self.dropout(encoded_des)\n",
        "        encoded_des = torch.nn.functional.tanh(self.des_added_layer_2(encoded_des))\n",
        "        encoded_des = self.dropout(encoded_des)\n",
        "        encoded_des = torch.nn.functional.tanh(self.des_added_layer_3(encoded_des))\n",
        "        final_encoded_des = torch.nn.functional.tanh(self.des_added_layer_4(encoded_des))\n",
        "\n",
        "        # textual - Name\n",
        "        encoded_name = torch.tensor(name_encoded)\n",
        "        encoded_name = torch.nn.functional.tanh(self.name_added_layer_1(encoded_name))\n",
        "        encoded_name = self.dropout(encoded_name)\n",
        "        encoded_name = torch.nn.functional.tanh(self.name_added_layer_2(encoded_name))\n",
        "        encoded_name = torch.nn.functional.tanh(self.name_added_layer_3(encoded_name))\n",
        "        final_encoded_name = torch.nn.functional.relu(self.name_added_layer_4(encoded_name))\n",
        "\n",
        "        # concatination #\n",
        "        x = torch.cat((final_output_img, final_encoded_name, final_encoded_des, X), 1)\n",
        "\n",
        "        ## processing of joint representation ##    --- CONV/FC -> BatchNorm -> ReLu(or other activation) -> Dropout\n",
        "        x = torch.nn.functional.tanh(self.layer_1(x))\n",
        "        x = self.layer_2(x)\n",
        "        x = self.batch_norm_1(x)\n",
        "        x = torch.nn.functional.tanh(self.dropout(x))\n",
        "        x = self.layer_3(x)\n",
        "        x = self.batch_norm_2(x)\n",
        "        x = torch.nn.functional.tanh(self.dropout(x))\n",
        "        x = torch.nn.functional.tanh(self.layer_4(x))\n",
        "        x = self.layer_5(x)\n",
        "\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "ujIJCIkxqxz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_name = \"discriminator_sparse_2_cont_again.pth\"\n",
        "\n",
        "path = \"/content/gdrive/My Drive/Thesis/Models/{}\".format(model_save_name)\n",
        "model_cont = torch.load(path) ## map_location=torch.device('cpu'))"
      ],
      "metadata": {
        "id": "VWLURft-XFDd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up a dataloader and creating predictions for DistilBART\n"
      ],
      "metadata": {
        "id": "aHFbXm5Iz2nH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conterfac_dataset = Simple_Dataset(airbnb_london_filtered_images_imp_var_titles)"
      ],
      "metadata": {
        "id": "rrwUzeoyQPT_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,j in enumerate(airbnb_london_filtered_images_imp_var_titles.columns):\n",
        "  print(f\"At position {str(i)} : variable {str(j)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KA_Q0YxJzgEw",
        "outputId": "cfef1994-4795-4da8-ae89-9b4b1f5c49fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At position 0 : variable number_of_reviews_ltm\n",
            "At position 1 : variable room_type\n",
            "At position 2 : variable reviews_per_month\n",
            "At position 3 : variable has_amenity_Iron\n",
            "At position 4 : variable Tower Hamlets\n",
            "At position 5 : variable price\n",
            "At position 6 : variable minimum_nights\n",
            "At position 7 : variable has_amenity_Cooking basics\n",
            "At position 8 : variable Enfield\n",
            "At position 9 : variable Kensington and Chelsea\n",
            "At position 10 : variable Islington\n",
            "At position 11 : variable Wandsworth\n",
            "At position 12 : variable Southwark\n",
            "At position 13 : variable has_amenity_Elevator\n",
            "At position 14 : variable number_of_reviews\n",
            "At position 15 : variable has_amenity_Kitchen\n",
            "At position 16 : variable has_amenity_Hair dryer\n",
            "At position 17 : variable Lambeth\n",
            "At position 18 : variable bedrooms\n",
            "At position 19 : variable has_amenity_Refrigerator\n",
            "At position 20 : variable Newham\n",
            "At position 21 : variable has_amenity_Heating\n",
            "At position 22 : variable has_amenity_Hot water\n",
            "At position 23 : variable len_description\n",
            "At position 24 : variable Hillingdon\n",
            "At position 25 : variable Lewisham\n",
            "At position 26 : variable Brent\n",
            "At position 27 : variable len_amenities\n",
            "At position 28 : variable Hackney\n",
            "At position 29 : variable Bromley\n",
            "At position 30 : variable Bexley\n",
            "At position 31 : variable has_amenity_Stove\n",
            "At position 32 : variable price_per_accomodate\n",
            "At position 33 : variable has_amenity_Smoke alarm\n",
            "At position 34 : variable has_amenity_TV\n",
            "At position 35 : variable Barking and Dagenham\n",
            "At position 36 : variable Ealing\n",
            "At position 37 : variable review_scores_rating\n",
            "At position 38 : variable beds\n",
            "At position 39 : variable has_amenity_Free parking on premises\n",
            "At position 40 : variable has_amenity_Wifi\n",
            "At position 41 : variable has_amenity_Shampoo\n",
            "At position 42 : variable has_amenity_Host greets you\n",
            "At position 43 : variable Westminster\n",
            "At position 44 : variable Richmond upon Thames\n",
            "At position 45 : variable Camden\n",
            "At position 46 : variable has_amenity_Microwave\n",
            "At position 47 : variable Hammersmith and Fulham\n",
            "At position 48 : variable Croydon\n",
            "At position 49 : variable has_amenity_Fire extinguisher\n",
            "At position 50 : variable has_amenity_Hangers\n",
            "At position 51 : variable has_amenity_First aid kit\n",
            "At position 52 : variable Waltham Forest\n",
            "At position 53 : variable has_amenity_Extra pillows and blankets\n",
            "At position 54 : variable has_amenity_Oven\n",
            "At position 55 : variable maximum_nights\n",
            "At position 56 : variable in_inner_boundary\n",
            "At position 57 : variable has_amenity_Private entrance\n",
            "At position 58 : variable has_amenity_Coffee maker\n",
            "At position 59 : variable has_amenity_Washer\n",
            "At position 60 : variable has_amenity_Essentials\n",
            "At position 61 : variable has_amenity_Dryer\n",
            "At position 62 : variable id\n",
            "At position 63 : variable name\n",
            "At position 64 : variable joint_description\n",
            "At position 65 : variable proxy\n",
            "At position 66 : variable review_diff\n",
            "At position 67 : variable gen_titles_distilbart\n",
            "At position 68 : variable gen_titles_bart\n",
            "At position 69 : variable gen_titles_pegasus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch_counterfactual_distilbart(batch):\n",
        "\n",
        "  \"\"\"\n",
        "  Idx_model refers to the location of the genrated names for a specific model\n",
        "  \"\"\"\n",
        "\n",
        "  list_images = []   # for the images passed through extractor function\n",
        "  tabular_list = []\n",
        "  list_proxies = []\n",
        "  list_review_diff = []\n",
        "  list_distilbart_name = []\n",
        "  list_joint_description = []\n",
        "  list_ids = []\n",
        "\n",
        "  for data in batch:\n",
        "\n",
        "    # indexing the image pixels form the dict\n",
        "    list_images.append(dict_images[str(data[62])])\n",
        "\n",
        "    list_ids.append(data[62]) # for saving the predictions\n",
        "\n",
        "    tabular_list.append(data[:62]) ## locations of tabular data\n",
        "    if int(data[65]) == 1:  ## location of categorical proxy variable\n",
        "      list_proxies.append([1,0,0])\n",
        "    elif int(data[65]) == 2:\n",
        "      list_proxies.append([0,1,0])\n",
        "    elif int(data[65]) == 3:\n",
        "      list_proxies.append([0,0,1])\n",
        "\n",
        "    list_review_diff.append(data[66])  ## location of cont. review diff variable\n",
        "\n",
        "    list_joint_description.append(dict_des[str(data[62])])\n",
        "\n",
        "    list_distilbart_name.append(dict_titles_distilbart[str(data[62])])\n",
        "\n",
        "  list_images  = torch.tensor(list_images, dtype=torch.float32)\n",
        "  list_joint_description = torch.tensor(list_joint_description, dtype=torch.float32)\n",
        "  list_distilbart_name = torch.tensor(list_distilbart_name, dtype=torch.float32)\n",
        "  tabular_list = torch.tensor(tabular_list, dtype=torch.float32)\n",
        "  list_proxies = torch.tensor(list_proxies, dtype=torch.float32)\n",
        "\n",
        "  return list_images, list_distilbart_name, list_joint_description, tabular_list, list_proxies, list_review_diff, list_ids\n",
        "\n",
        "\n",
        "# images, names, des, tabular data, proxies, review_diff, ids\n"
      ],
      "metadata": {
        "id": "zx8K8xm20g3Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating counterfactuals for DistilBART generated titles"
      ],
      "metadata": {
        "id": "jjpOl0_cvPFh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dl_counterfactuals_distilbart = DataLoader(conterfac_dataset, collate_fn=collate_batch_counterfactual_distilbart, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "lnfqay6o2ydC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ys, preds_, ids = get_counterfactuals(model_cont, dl_counterfactuals_distilbart, True)\n",
        "preds = [a[0] for a in preds_]"
      ],
      "metadata": {
        "id": "sNBXUavp2-71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb31a556-74b9-44a7-a4c8-99fd3ba2b79d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-cd61884250f5>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  name = torch.tensor(batch[1]).to(device)\n",
            "<ipython-input-3-cd61884250f5>:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  joint_des = torch.tensor(batch[2]).to(device)\n",
            "<ipython-input-22-eb3a40074087>:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  encoded_des = torch.tensor(des_encoded)\n",
            "<ipython-input-22-eb3a40074087>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  encoded_name = torch.tensor(name_encoded)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cf_distilbart = pd.DataFrame({\"id\": ids, \"pred\": preds, \"Y\": Ys})\n",
        "#cf_distilbart.to_csv(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/cf_distilbart.csv\", index = False)"
      ],
      "metadata": {
        "id": "hDC4x_-bn6FN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cf_distilbart = pd.read_csv(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/cf_distilbart.csv\")\n"
      ],
      "metadata": {
        "id": "Ril69BsaGi4d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_preds_distilbart = pd.merge(airbnb_london_filtered_images_imp_var[[\"id\", \"proxy\"]], cf_distilbart, how = \"left\", on = \"id\")\n",
        "df_all_preds_distilbart[\"pred_real_name\"] = pred_disc_2_cont_real_name.pred\n"
      ],
      "metadata": {
        "id": "2cRvcQreADaQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checking differences of preidcted review diff based on true titles and predicted review diff based on generated titles"
      ],
      "metadata": {
        "id": "h6Nv6RGCBAWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "np.mean(df_all_preds_distilbart[df_all_preds_distilbart.proxy != 3].pred - df_all_preds_distilbart[df_all_preds_distilbart.proxy != 3].pred_real_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "393UR3imM6_l",
        "outputId": "bfea7329-33dc-425b-8292-3b80b0a61549"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.019353811836787346\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "permutation_test(df_all_preds_distilbart[df_all_preds_distilbart.proxy != 3].pred, df_all_preds_distilbart.pred_real_name[df_all_preds_distilbart.proxy != 3], 1000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_ShgNvUBOyE",
        "outputId": "7b8b7dd6-1e07-44b0-e84b-4b929ed44772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up a dataloader and creating predictions for BART\n"
      ],
      "metadata": {
        "id": "TSbWLJSfe9AN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conterfac_dataset  = Simple_Dataset(airbnb_london_filtered_images_imp_var_titles)"
      ],
      "metadata": {
        "id": "xUAI8k0Me9AS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i,j in enumerate(airbnb_london_filtered_images_imp_var_titles.columns):\n",
        "  print(f\"At position {str(i)} : variable {str(j)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae4c35f6-ffc6-4bba-9df8-708b023b9dfb",
        "id": "7bGLLrPTe9Ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "At position 0 : variable number_of_reviews_ltm\n",
            "At position 1 : variable room_type\n",
            "At position 2 : variable reviews_per_month\n",
            "At position 3 : variable has_amenity_Iron\n",
            "At position 4 : variable Tower Hamlets\n",
            "At position 5 : variable price\n",
            "At position 6 : variable minimum_nights\n",
            "At position 7 : variable has_amenity_Cooking basics\n",
            "At position 8 : variable Enfield\n",
            "At position 9 : variable Kensington and Chelsea\n",
            "At position 10 : variable Islington\n",
            "At position 11 : variable Wandsworth\n",
            "At position 12 : variable Southwark\n",
            "At position 13 : variable has_amenity_Elevator\n",
            "At position 14 : variable number_of_reviews\n",
            "At position 15 : variable has_amenity_Kitchen\n",
            "At position 16 : variable has_amenity_Hair dryer\n",
            "At position 17 : variable Lambeth\n",
            "At position 18 : variable bedrooms\n",
            "At position 19 : variable has_amenity_Refrigerator\n",
            "At position 20 : variable Newham\n",
            "At position 21 : variable has_amenity_Heating\n",
            "At position 22 : variable has_amenity_Hot water\n",
            "At position 23 : variable len_description\n",
            "At position 24 : variable Hillingdon\n",
            "At position 25 : variable Lewisham\n",
            "At position 26 : variable Brent\n",
            "At position 27 : variable len_amenities\n",
            "At position 28 : variable Hackney\n",
            "At position 29 : variable Bromley\n",
            "At position 30 : variable Bexley\n",
            "At position 31 : variable has_amenity_Stove\n",
            "At position 32 : variable price_per_accomodate\n",
            "At position 33 : variable has_amenity_Smoke alarm\n",
            "At position 34 : variable has_amenity_TV\n",
            "At position 35 : variable Barking and Dagenham\n",
            "At position 36 : variable Ealing\n",
            "At position 37 : variable review_scores_rating\n",
            "At position 38 : variable beds\n",
            "At position 39 : variable has_amenity_Free parking on premises\n",
            "At position 40 : variable has_amenity_Wifi\n",
            "At position 41 : variable has_amenity_Shampoo\n",
            "At position 42 : variable has_amenity_Host greets you\n",
            "At position 43 : variable Westminster\n",
            "At position 44 : variable Richmond upon Thames\n",
            "At position 45 : variable Camden\n",
            "At position 46 : variable has_amenity_Microwave\n",
            "At position 47 : variable Hammersmith and Fulham\n",
            "At position 48 : variable Croydon\n",
            "At position 49 : variable has_amenity_Fire extinguisher\n",
            "At position 50 : variable has_amenity_Hangers\n",
            "At position 51 : variable has_amenity_First aid kit\n",
            "At position 52 : variable Waltham Forest\n",
            "At position 53 : variable has_amenity_Extra pillows and blankets\n",
            "At position 54 : variable has_amenity_Oven\n",
            "At position 55 : variable maximum_nights\n",
            "At position 56 : variable in_inner_boundary\n",
            "At position 57 : variable has_amenity_Private entrance\n",
            "At position 58 : variable has_amenity_Coffee maker\n",
            "At position 59 : variable has_amenity_Washer\n",
            "At position 60 : variable has_amenity_Essentials\n",
            "At position 61 : variable has_amenity_Dryer\n",
            "At position 62 : variable id\n",
            "At position 63 : variable name\n",
            "At position 64 : variable joint_description\n",
            "At position 65 : variable proxy\n",
            "At position 66 : variable review_diff\n",
            "At position 67 : variable gen_titles_distilbart\n",
            "At position 68 : variable gen_titles_bart\n",
            "At position 69 : variable gen_titles_pegasus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch_counterfactual_bart(batch):\n",
        "\n",
        "  \"\"\"\n",
        "  Idx_model refers to the location of the genrated names for a specific model\n",
        "  \"\"\"\n",
        "\n",
        "  list_images = []   # for the images passed through extractor function\n",
        "  tabular_list = []\n",
        "  list_proxies = []\n",
        "  list_review_diff = []\n",
        "  list_distilbart_name = []\n",
        "  list_joint_description = []\n",
        "  list_ids = []\n",
        "\n",
        "  for data in batch:\n",
        "\n",
        "    # indexing the image pixels form the dict\n",
        "    list_images.append(dict_images[str(data[62])])\n",
        "\n",
        "    list_ids.append(data[62]) # for saving the predictions\n",
        "\n",
        "    tabular_list.append(data[:62]) ## locations of tabular data\n",
        "    if int(data[65]) == 1:  ## location of categorical proxy variable\n",
        "      list_proxies.append([1,0,0])\n",
        "    elif int(data[65]) == 2:\n",
        "      list_proxies.append([0,1,0])\n",
        "    elif int(data[65]) == 3:\n",
        "      list_proxies.append([0,0,1])\n",
        "\n",
        "    list_review_diff.append(data[66])  ## location of cont. review diff variable\n",
        "\n",
        "    list_joint_description.append(dict_des[str(data[62])])\n",
        "\n",
        "    list_distilbart_name.append(dict_titles_bart[str(data[62])])\n",
        "\n",
        "  list_images  = torch.tensor(list_images, dtype=torch.float32)\n",
        "  list_joint_description = torch.tensor(list_joint_description, dtype=torch.float32)\n",
        "  list_distilbart_name = torch.tensor(list_distilbart_name, dtype=torch.float32)\n",
        "  tabular_list = torch.tensor(tabular_list, dtype=torch.float32)\n",
        "  list_proxies = torch.tensor(list_proxies, dtype=torch.float32)\n",
        "\n",
        "  return list_images, list_distilbart_name, list_joint_description, tabular_list, list_proxies, list_review_diff, list_ids\n",
        "\n",
        "\n",
        "# images, names, des, tabular data, proxies, review_diff, ids\n"
      ],
      "metadata": {
        "id": "01GNpzF1e9Ag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating counterfactuals for BART generated titles\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RGapp5ONe9Am"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dl_counterfactuals_bart = DataLoader(conterfac_dataset, collate_fn=collate_batch_counterfactual_bart, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "b-4749Jve9Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ys, preds_, ids = get_counterfactuals(model_cont, dl_counterfactuals_bart, True)\n",
        "preds = [a[0] for a in preds_]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ccbf878-c623-441d-a720-e93451d5ad7d",
        "id": "3zu9mhoMe9At"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-30-72dff8073080>:39: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  tabular_list = torch.tensor(tabular_list, dtype=torch.float32)\n",
            "<ipython-input-3-cd61884250f5>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  name = torch.tensor(batch[1]).to(device)\n",
            "<ipython-input-3-cd61884250f5>:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  joint_des = torch.tensor(batch[2]).to(device)\n",
            "<ipython-input-24-db5eea07eaf4>:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  encoded_des = torch.tensor(des_encoded)\n",
            "<ipython-input-24-db5eea07eaf4>:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  encoded_name = torch.tensor(name_encoded)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cf_bart = pd.DataFrame({\"id\": ids, \"pred\": preds, \"Y\": Ys})\n",
        "#cf_bart.to_csv(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/cf_bart.csv\", index = False)"
      ],
      "metadata": {
        "id": "xF9hOgQue9Aw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_preds_bart = pd.merge(airbnb_london_filtered_images_imp_var[[\"id\", \"proxy\"]], cf_bart, how = \"left\", on = \"id\")\n",
        "df_all_preds_bart[\"pred_real_name\"] = pred_disc_2_cont_real_name.pred\n"
      ],
      "metadata": {
        "id": "wqAsvE48e9A3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checking differences of preidcted review diff based on true titles and predicted review diff based on generated titles"
      ],
      "metadata": {
        "id": "C-0iDiT2e9A5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###\n",
        "\n",
        "np.mean(df_all_preds_bart[df_all_preds_bart.proxy != 3].pred - df_all_preds_bart[df_all_preds_bart.proxy != 3].pred_real_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NqPxLqQMzVy",
        "outputId": "43954615-31e9-4b18-aa85-a5bf79973fb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.019314348749710336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "permutation_test(df_all_preds_bart[df_all_preds_bart.proxy != 3].pred, df_all_preds_bart.pred_real_name[df_all_preds_bart.proxy != 3], 1000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "15576733-2fe4-41d5-be7f-cb87c9cadf50",
        "id": "XxqtOTPme9A-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.824\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up a dataloader and creating predictions for Pegasus\n"
      ],
      "metadata": {
        "id": "hjs9h18Hp6BT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conterfac_dataset  = Simple_Dataset(airbnb_london_filtered_images_imp_var_titles)"
      ],
      "metadata": {
        "id": "OrTEcVVTp6Bh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#for i,j in enumerate(airbnb_london_filtered_images_imp_var_titles.columns):\n",
        "  #print(f\"At position {str(i)} : variable {str(j)}\") # so above!"
      ],
      "metadata": {
        "id": "WADvlMQXp6Bo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch_counterfactual_pegasus(batch):\n",
        "\n",
        "  \"\"\"\n",
        "  Idx_model refers to the location of the genrated names for a specific model\n",
        "  \"\"\"\n",
        "\n",
        "  list_images = []   # for the images passed through extractor function\n",
        "  tabular_list = []\n",
        "  list_proxies = []\n",
        "  list_review_diff = []\n",
        "  list_distilbart_name = []\n",
        "  list_joint_description = []\n",
        "  list_ids = []\n",
        "\n",
        "  for data in batch:\n",
        "\n",
        "    # indexing the image pixels form the dict\n",
        "    list_images.append(dict_images[str(data[62])])\n",
        "\n",
        "    list_ids.append(data[62]) # for saving the predictions\n",
        "\n",
        "    tabular_list.append(data[:62]) ## locations of tabular data\n",
        "    if int(data[65]) == 1:  ## location of categorical proxy variable\n",
        "      list_proxies.append([1,0,0])\n",
        "    elif int(data[65]) == 2:\n",
        "      list_proxies.append([0,1,0])\n",
        "    elif int(data[65]) == 3:\n",
        "      list_proxies.append([0,0,1])\n",
        "\n",
        "    list_review_diff.append(data[66])  ## location of cont. review diff variable\n",
        "\n",
        "    list_joint_description.append(dict_des[str(data[62])])\n",
        "\n",
        "    list_distilbart_name.append(dict_titles_pegasus[str(data[62])])    # only change here!\n",
        "\n",
        "  list_images  = torch.tensor(list_images, dtype=torch.float32)\n",
        "  list_joint_description = torch.tensor(list_joint_description, dtype=torch.float32)\n",
        "  list_distilbart_name = torch.tensor(list_distilbart_name, dtype=torch.float32)\n",
        "  tabular_list = torch.tensor(tabular_list, dtype=torch.float32)\n",
        "  list_proxies = torch.tensor(list_proxies, dtype=torch.float32)\n",
        "\n",
        "  return list_images, list_distilbart_name, list_joint_description, tabular_list, list_proxies, list_review_diff, list_ids\n",
        "\n",
        "\n",
        "# images, names, des, tabular data, proxies, review_diff, ids\n"
      ],
      "metadata": {
        "id": "QfseIibjp6Bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating counterfactuals for PEGASUS generated titles"
      ],
      "metadata": {
        "id": "QqmRsX1Kp6B2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dl_counterfactuals_pegasus = DataLoader(conterfac_dataset, collate_fn=collate_batch_counterfactual_pegasus, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "eXdFvFdvp6CB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ys, preds_, ids = get_counterfactuals(model_cont, dl_counterfactuals_pegasus, True)\n",
        "preds = [a[0] for a in preds_]"
      ],
      "metadata": {
        "id": "I1SuyNEpp6CF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9c14b6d-0368-4a35-a06c-6434b0c846fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-fcb093bee07b>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  name = torch.tensor(batch[1]).to(device)\n",
            "<ipython-input-3-fcb093bee07b>:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  joint_des = torch.tensor(batch[2]).to(device)\n",
            "<ipython-input-12-aa97a71ee220>:78: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  encoded_des = torch.tensor(des_encoded)\n",
            "<ipython-input-12-aa97a71ee220>:87: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  encoded_name = torch.tensor(name_encoded)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cf_pegasus = pd.DataFrame({\"id\": ids, \"pred\": preds, \"Y\": Ys})\n",
        "#cf_pegasus.to_csv(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/cf_distilbart.csv\", index = False)"
      ],
      "metadata": {
        "id": "cPA9xOg8p6CK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_preds_peg = pd.merge(airbnb_london_filtered_images_imp_var[[\"id\", \"proxy\"]], cf_pegasus, how = \"left\", on = \"id\")\n",
        "df_all_preds_peg[\"pred_real_name\"] = pred_disc_2_cont_real_name.pred\n"
      ],
      "metadata": {
        "id": "8zlTyVEHp6CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checking differences of preidcted review diff based on true titles and predicted review diff based on generated titles"
      ],
      "metadata": {
        "id": "UMA8e3x0p6Cb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "np.mean(df_all_preds_peg[df_all_preds_peg.proxy != 3].pred - df_all_preds_peg[df_all_preds_peg.proxy != 3].pred_real_name)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWH6couNMsJG",
        "outputId": "d27484fe-b50b-4c7b-865e-67c5451f0448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.019454615010690904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "permutation_test(df_all_preds_peg[df_all_preds_peg.proxy != 3].pred, df_all_preds_peg.pred_real_name[df_all_preds_peg.proxy != 3], 1000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5240a3b9-1d25-43bb-8b1c-412280710adf",
        "id": "kRQAFQHyp6Cp"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.331"
            ]
          },
          "metadata": {},
          "execution_count": 300
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LlaMa Generation 1"
      ],
      "metadata": {
        "id": "tPxdpdfmAWxH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LLama LORA"
      ],
      "metadata": {
        "id": "fHtKUS-zAWxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_titles_llama_lora = pd.read_csv(\"/content/gdrive/My Drive/Thesis/loss_data/gen_titles_llama.csv\")"
      ],
      "metadata": {
        "id": "D0fTLzVhAWxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# as I have fewer generated titles with LLaMa LLora\n",
        "airbnb_london_filtered_images_imp_var_titles_with_llama_lora = pd.merge(airbnb_london_filtered_images_imp_var_titles,  gen_titles_llama_lora, how = \"inner\", on = \"id\")\n",
        "\n",
        "conterfac_dataset  = Simple_Dataset(airbnb_london_filtered_images_imp_var_titles_with_llama_lora)\n"
      ],
      "metadata": {
        "id": "SNYq1oUUAWxQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch_counterfactual_llama_lora(batch):\n",
        "\n",
        "  \"\"\"\n",
        "  Idx_model refers to the location of the genrated names for a specific model\n",
        "  \"\"\"\n",
        "\n",
        "  list_images = []   # for the images passed through extractor function\n",
        "  tabular_list = []\n",
        "  list_proxies = []\n",
        "  list_review_diff = []\n",
        "  list_distilbart_name = []\n",
        "  list_joint_description = []\n",
        "  list_ids = []\n",
        "\n",
        "  for data in batch:\n",
        "\n",
        "    # indexing the image pixels form the dict\n",
        "    list_images.append(dict_images[str(data[62])])\n",
        "\n",
        "    list_ids.append(data[62]) # for saving the predictions\n",
        "\n",
        "    tabular_list.append(data[:62]) ## locations of tabular data\n",
        "    if int(data[65]) == 1:  ## location of categorical proxy variable\n",
        "      list_proxies.append([1,0,0])\n",
        "    elif int(data[65]) == 2:\n",
        "      list_proxies.append([0,1,0])\n",
        "    elif int(data[65]) == 3:\n",
        "      list_proxies.append([0,0,1])\n",
        "\n",
        "    list_review_diff.append(data[66])  ## location of cont. review diff variable\n",
        "\n",
        "    list_joint_description.append(dict_des[str(data[62])])\n",
        "\n",
        "    list_distilbart_name.append(dict_titles_llama_lora[str(data[62])])    # only change here!\n",
        "\n",
        "  list_images  = torch.tensor(list_images, dtype=torch.float32)\n",
        "  list_joint_description = torch.tensor(list_joint_description, dtype=torch.float32)\n",
        "  list_distilbart_name = torch.tensor(list_distilbart_name, dtype=torch.float32)\n",
        "  tabular_list = torch.tensor(tabular_list, dtype=torch.float32)\n",
        "  list_proxies = torch.tensor(list_proxies, dtype=torch.float32)\n",
        "\n",
        "  return list_images, list_distilbart_name, list_joint_description, tabular_list, list_proxies, list_review_diff, list_ids\n",
        "\n",
        "\n",
        "# images, names, des, tabular data, proxies, review_diff, ids\n"
      ],
      "metadata": {
        "id": "1tWN-TvoAWxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating counterfactuals for LLAMA (LoRa) generated titles"
      ],
      "metadata": {
        "id": "WS2uyGtTAWxW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dl_counterfactuals_llama_lora = DataLoader(conterfac_dataset, collate_fn=collate_batch_counterfactual_llama_lora, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "vJdq8cm3AWxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ys, preds_, ids = get_counterfactuals(model_cont, dl_counterfactuals_llama_lora, True)\n",
        "preds = [a[0] for a in preds_]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d02c5f4b-d5dc-4c62-c4bc-c919ee24aa1d",
        "id": "BhzvWvmuAWxa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-fb29812b7e7c>:39: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  tabular_list = torch.tensor(tabular_list, dtype=torch.float32)\n",
            "<ipython-input-3-cd61884250f5>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  name = torch.tensor(batch[1]).to(device)\n",
            "<ipython-input-3-cd61884250f5>:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  joint_des = torch.tensor(batch[2]).to(device)\n",
            "<ipython-input-12-eb3a40074087>:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  encoded_des = torch.tensor(des_encoded)\n",
            "<ipython-input-12-eb3a40074087>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  encoded_name = torch.tensor(name_encoded)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cf_llama_lora = pd.DataFrame({\"id\": ids, \"pred\": preds, \"Y\": Ys})\n",
        "#cf_llama_lora.to_csv(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/cf_distilbart.csv\", index = False)"
      ],
      "metadata": {
        "id": "EreQbWX1AWxf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#cf_distilbart = pd.read_csv(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/cf_distilbart.csv\")\n"
      ],
      "metadata": {
        "id": "x9yxurI9AWxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_preds_llama_lora = pd.merge(airbnb_london_filtered_images_imp_var_titles_with_llama_lora[[\"id\", \"proxy\"]], cf_llama_lora, how = \"left\", on = \"id\")\n"
      ],
      "metadata": {
        "id": "lFVCxQ4nAWxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_preds_llama_lora = pd.merge(df_all_preds_llama_lora, pred_disc_2_cont_real_name[[\"id\", \"pred\"]], on = \"id\", how = \"inner\")"
      ],
      "metadata": {
        "id": "mb4UPba4AWxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checking differences of preidcted review diff based on true titles and predicted review diff based on generated titles"
      ],
      "metadata": {
        "id": "ZA0rBlrtAWxl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###  ## x is is generated  tittle, y is true title\n",
        "\n",
        "\n",
        "np.mean(df_all_preds_llama_lora[df_all_preds_llama_lora.proxy != 3].pred_x - df_all_preds_llama_lora[df_all_preds_llama_lora.proxy != 3].pred_y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ea0be4d-c071-4183-b31a-6162d17ff8d1",
        "id": "IhHKOgP1AWxn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.033025576656099606"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also checking result of permutation test based on proxy value"
      ],
      "metadata": {
        "id": "7YyX63DMAWxp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "permutation_test(df_all_preds_llama_lora[df_all_preds_llama_lora.proxy != 3].pred_x, df_all_preds_llama_lora[df_all_preds_llama_lora.proxy != 3].pred_y, 1000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "831b0e36-d840-491e-bb53-89085629143a",
        "id": "pSWrS6UvAWxq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.103"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LLama-Adapter"
      ],
      "metadata": {
        "id": "oyRy0RVNAWxs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_titles_llama_adapter = pd.read_csv(\"/content/gdrive/My Drive/Thesis/loss_data/gen_titles_llama_adapter.csv\")\n"
      ],
      "metadata": {
        "id": "6y_SEmlDAWxt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gen_titles_llama_adapter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "90f73629-615b-4951-ef0c-bd6591c0ecf7",
        "id": "U-DSV7i0AWxu"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           id                                         gen_titles\n",
              "0    19443194       Explore this stunning two bed flat in Fulham\n",
              "1    14071318              Bright, spacious, central London flat\n",
              "2    23847732      Central 2 Bedroom Flat with a lovely terrace!\n",
              "3    38260808                      Cozy room in a welcoming home\n",
              "4     9531664               Double close to Leyton ST/Leyton STC\n",
              "..        ...                                                ...\n",
              "995   6704485       Private room with ensuite in Clapham High St\n",
              "996  53035936  Modern Self Contained Studio Nestled in Privat...\n",
              "997   3305771                     East London with private space\n",
              "998  34339339               Lovely Size Double Room in Stratford\n",
              "999  25282792  Bright and stylish 2 bed apartment in East London\n",
              "\n",
              "[1000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d33ccd2d-cace-4750-a620-dcd5ac444aa1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>gen_titles</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>19443194</td>\n",
              "      <td>Explore this stunning two bed flat in Fulham</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14071318</td>\n",
              "      <td>Bright, spacious, central London flat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23847732</td>\n",
              "      <td>Central 2 Bedroom Flat with a lovely terrace!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>38260808</td>\n",
              "      <td>Cozy room in a welcoming home</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9531664</td>\n",
              "      <td>Double close to Leyton ST/Leyton STC</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>6704485</td>\n",
              "      <td>Private room with ensuite in Clapham High St</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>53035936</td>\n",
              "      <td>Modern Self Contained Studio Nestled in Privat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>3305771</td>\n",
              "      <td>East London with private space</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>34339339</td>\n",
              "      <td>Lovely Size Double Room in Stratford</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>25282792</td>\n",
              "      <td>Bright and stylish 2 bed apartment in East London</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d33ccd2d-cace-4750-a620-dcd5ac444aa1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d33ccd2d-cace-4750-a620-dcd5ac444aa1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d33ccd2d-cace-4750-a620-dcd5ac444aa1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# as I have fewer generated titles with LLaMa LLora\n",
        "airbnb_london_filtered_images_imp_var_titles_with_llama_adapter = pd.merge(airbnb_london_filtered_images_imp_var_titles,  gen_titles_llama_adapter, how = \"inner\", on = \"id\")\n",
        "conterfac_dataset  = Simple_Dataset(airbnb_london_filtered_images_imp_var_titles_with_llama_adapter)\n"
      ],
      "metadata": {
        "id": "ORwX93aaAWxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch_counterfactual_llama_adapter(batch):\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  Idx_model refers to the location of the genrated names for a specific model\n",
        "  \"\"\"\n",
        "\n",
        "  list_images = []   # for the images passed through extractor function\n",
        "  tabular_list = []\n",
        "  list_proxies = []\n",
        "  list_review_diff = []\n",
        "  list_llama_adapter_name = []\n",
        "  list_joint_description = []\n",
        "  list_ids = []\n",
        "\n",
        "  for data in batch:\n",
        "\n",
        "    # indexing the image pixels form the dict\n",
        "    list_images.append(dict_images[str(data[62])])\n",
        "\n",
        "    list_ids.append(data[62]) # for saving the predictions\n",
        "\n",
        "    tabular_list.append(data[:62]) ## locations of tabular data\n",
        "    if int(data[65]) == 1:  ## location of categorical proxy variable\n",
        "      list_proxies.append([1,0,0])\n",
        "    elif int(data[65]) == 2:\n",
        "      list_proxies.append([0,1,0])\n",
        "    elif int(data[65]) == 3:\n",
        "      list_proxies.append([0,0,1])\n",
        "\n",
        "    list_review_diff.append(data[66])  ## location of cont. review diff variable\n",
        "\n",
        "    list_joint_description.append(dict_des[str(data[62])])\n",
        "\n",
        "    list_llama_adapter_name.append(dict_titles_llama_adapter[str(data[62])])    # only change here!\n",
        "\n",
        "  list_images  = torch.tensor(list_images, dtype=torch.float32)\n",
        "  list_joint_description = torch.tensor(list_joint_description, dtype=torch.float32)\n",
        "  list_llama_adapter_name = torch.tensor(list_llama_adapter_name, dtype=torch.float32)\n",
        "  tabular_list = torch.tensor(tabular_list, dtype=torch.float32)\n",
        "  list_proxies = torch.tensor(list_proxies, dtype=torch.float32)\n",
        "\n",
        "  return list_images, list_llama_adapter_name, list_joint_description, tabular_list, list_proxies, list_review_diff, list_ids\n",
        "\n",
        "\n",
        "# images, names, des, tabular data, proxies, review_diff, ids\n"
      ],
      "metadata": {
        "id": "wi1ePSKkAWxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating counterfactuals for LLAMA-Adapter generated titles"
      ],
      "metadata": {
        "id": "kN-W6SK6AWxz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dl_counterfactuals_llama_adapter = DataLoader(conterfac_dataset, collate_fn=collate_batch_counterfactual_llama_adapter, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "bwzqELd3AWxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ys, preds_, ids = get_counterfactuals(model_cont, dl_counterfactuals_llama_adapter, True)\n",
        "preds = [a[0] for a in preds_]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8bef10ea-7faf-4487-e9c2-6980381647d5",
        "id": "itFHuSnVAWx1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-8f172eb205a4>:40: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  tabular_list = torch.tensor(tabular_list, dtype=torch.float32)\n",
            "<ipython-input-3-cd61884250f5>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  name = torch.tensor(batch[1]).to(device)\n",
            "<ipython-input-3-cd61884250f5>:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  joint_des = torch.tensor(batch[2]).to(device)\n",
            "<ipython-input-13-eb3a40074087>:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  encoded_des = torch.tensor(des_encoded)\n",
            "<ipython-input-13-eb3a40074087>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  encoded_name = torch.tensor(name_encoded)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cf_llama_adapter = pd.DataFrame({\"id\": ids, \"pred\": preds, \"Y\": Ys})\n",
        "#cf_llama_adapter.to_csv(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/cf_distilbart.csv\", index = False)"
      ],
      "metadata": {
        "id": "6v-htgd6AWx3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_preds_llama_adapter = pd.merge(airbnb_london_filtered_images_imp_var_titles_with_llama_adapter[[\"id\", \"proxy\"]], cf_llama_adapter, how = \"left\", on = \"id\")\n"
      ],
      "metadata": {
        "id": "vNrvrEomAWx4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_preds_llama_adapter = pd.merge(df_all_preds_llama_adapter, pred_disc_2_cont_real_name[[\"id\", \"pred\"]], on = \"id\", how = \"inner\")"
      ],
      "metadata": {
        "id": "rZw2ACyyAWx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checking differences of preidcted review diff based on true titles and predicted review diff based on generated titles"
      ],
      "metadata": {
        "id": "H3IRGZwVAWx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###  ## x is is generated  tittle, y is true title\n",
        "\n",
        "np.mean(df_all_preds_llama_adapter[df_all_preds_llama_adapter.proxy != 3].pred_x - df_all_preds_llama_adapter[df_all_preds_llama_adapter.proxy != 3].pred_y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71f611d5-df80-4031-84cf-b91af386e4c4",
        "id": "Opz--oBmAWx7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.031121540145025196"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "permutation_test(df_all_preds_llama_adapter[df_all_preds_llama_adapter.proxy != 3].pred_x, df_all_preds_llama_adapter[df_all_preds_llama_adapter.proxy != 3].pred_y, 1000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33dd8afe-d10a-44fa-c947-8408790c4a10",
        "id": "kLL4dSvgAWx9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.124"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LLama (no PEFT)"
      ],
      "metadata": {
        "id": "8Z1WlaJNAWx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_titles_llama_no_peft = pd.read_csv(\"/content/gdrive/My Drive/Thesis/loss_data/gen_titles_llama_no_peft.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "BMNeaGXoAWyA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# as I have fewer generated titles with LLaMa LLora\n",
        "airbnb_london_filtered_images_imp_var_titles_with_llama_no_peft = pd.merge(airbnb_london_filtered_images_imp_var_titles,  gen_titles_llama_no_peft, how = \"inner\", on = \"id\")\n",
        "conterfac_dataset  = Simple_Dataset(airbnb_london_filtered_images_imp_var_titles_with_llama_no_peft)\n"
      ],
      "metadata": {
        "id": "wsJ8KwfxAWyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch_counterfactual_llama_no_peft(batch):\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  Idx_model refers to the location of the genrated names for a specific model\n",
        "  \"\"\"\n",
        "\n",
        "  list_images = []   # for the images passed through extractor function\n",
        "  tabular_list = []\n",
        "  list_proxies = []\n",
        "  list_review_diff = []\n",
        "  list_llama_adapter_name = []\n",
        "  list_joint_description = []\n",
        "  list_ids = []\n",
        "\n",
        "  for data in batch:\n",
        "\n",
        "    # indexing the image pixels form the dict\n",
        "    list_images.append(dict_images[str(data[62])])\n",
        "\n",
        "    list_ids.append(data[62]) # for saving the predictions\n",
        "\n",
        "    tabular_list.append(data[:62]) ## locations of tabular data\n",
        "    if int(data[65]) == 1:  ## location of categorical proxy variable\n",
        "      list_proxies.append([1,0,0])\n",
        "    elif int(data[65]) == 2:\n",
        "      list_proxies.append([0,1,0])\n",
        "    elif int(data[65]) == 3:\n",
        "      list_proxies.append([0,0,1])\n",
        "\n",
        "    list_review_diff.append(data[66])  ## location of cont. review diff variable\n",
        "\n",
        "    list_joint_description.append(dict_des[str(data[62])])\n",
        "\n",
        "    list_llama_adapter_name.append(dict_titles_llama_no_peft[str(data[62])])    # only change here!\n",
        "\n",
        "  list_images  = torch.tensor(list_images, dtype=torch.float32)\n",
        "  list_joint_description = torch.tensor(list_joint_description, dtype=torch.float32)\n",
        "  list_llama_adapter_name = torch.tensor(list_llama_adapter_name, dtype=torch.float32)\n",
        "  tabular_list = torch.tensor(tabular_list, dtype=torch.float32)\n",
        "  list_proxies = torch.tensor(list_proxies, dtype=torch.float32)\n",
        "\n",
        "  return list_images, list_llama_adapter_name, list_joint_description, tabular_list, list_proxies, list_review_diff, list_ids\n",
        "\n",
        "\n",
        "# images, names, des, tabular data, proxies, review_diff, ids\n"
      ],
      "metadata": {
        "id": "x_VLQTAjAWyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating counterfactuals for LLAMA generated titles (no peft)"
      ],
      "metadata": {
        "id": "j_o51UVZAWyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dl_counterfactuals_llama_no_peft = DataLoader(conterfac_dataset, collate_fn=collate_batch_counterfactual_llama_no_peft, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "Q3sOTv1NAWyG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ys, preds_, ids = get_counterfactuals(model_cont, dl_counterfactuals_llama_no_peft, True)\n",
        "preds = [a[0] for a in preds_]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2332b05-4f2b-45f3-a2d6-7b4c49b3aa15",
        "id": "lwfWFSGTAWyH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-47-cd61884250f5>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  name = torch.tensor(batch[1]).to(device)\n",
            "<ipython-input-47-cd61884250f5>:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  joint_des = torch.tensor(batch[2]).to(device)\n",
            "<ipython-input-62-eb3a40074087>:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  encoded_des = torch.tensor(des_encoded)\n",
            "<ipython-input-62-eb3a40074087>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  encoded_name = torch.tensor(name_encoded)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cf_llama_no_peft = pd.DataFrame({\"id\": ids, \"pred\": preds, \"Y\": Ys})\n"
      ],
      "metadata": {
        "id": "ra618QfoAWyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_preds_llama_no_peft = pd.merge(airbnb_london_filtered_images_imp_var_titles_with_llama_no_peft[[\"id\", \"proxy\"]], cf_llama_no_peft, how = \"left\", on = \"id\")\n"
      ],
      "metadata": {
        "id": "CE4-NEdaAWyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_preds_llama_no_peft = pd.merge(df_all_preds_llama_no_peft, pred_disc_2_cont_real_name[[\"id\", \"pred\"]], on = \"id\", how = \"inner\")"
      ],
      "metadata": {
        "id": "xdzzIFfXAWyM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checking differences of preidcted review diff based on true titles and predicted review diff based on generated titles"
      ],
      "metadata": {
        "id": "HjkK-YR3AWyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###  ## x is is generated  tittle, y is true title\n",
        "\n",
        "np.mean(df_all_preds_llama_no_peft[df_all_preds_llama_no_peft.proxy != 3].pred_x - df_all_preds_llama_no_peft[df_all_preds_llama_no_peft.proxy != 3].pred_y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8f0f91c-ba02-4276-8dd1-a8fa50e11249",
        "id": "Awf5thCYAWyN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-0.0011023467394448393"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "permutation_test(df_all_preds_llama_no_peft[df_all_preds_llama_no_peft.proxy != 3].pred_x, df_all_preds_llama_no_peft[df_all_preds_llama_no_peft.proxy != 3].pred_y, 1000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "990dd60c-ec1c-4bdd-f8ba-04aedf333ae1",
        "id": "C1SEfO8hAWyP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LlaMa Generation 2"
      ],
      "metadata": {
        "id": "7jbvpgVcG00f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LLama LORA"
      ],
      "metadata": {
        "id": "VkiKDWjEG00l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_titles_llama_lora_v2 = pd.read_csv(\"/content/gdrive/My Drive/Thesis/loss_data/gen_titles_llama_v2.csv\")"
      ],
      "metadata": {
        "id": "0i41QfRhG00o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uC4CPOzIYJHK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# as I have fewer generated titles with LLaMa LLora\n",
        "airbnb_london_filtered_images_imp_var_titles_with_llama_lora_v2 = pd.merge(airbnb_london_filtered_images_imp_var_titles,  gen_titles_llama_lora_v2, how = \"inner\", on = \"id\")\n",
        "\n",
        "conterfac_dataset  = Simple_Dataset(airbnb_london_filtered_images_imp_var_titles_with_llama_lora_v2)\n"
      ],
      "metadata": {
        "id": "lXcGeAHqG00r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch_counterfactual_llama_lora_v2(batch):\n",
        "\n",
        "  \"\"\"\n",
        "  Idx_model refers to the location of the genrated names for a specific model\n",
        "  \"\"\"\n",
        "\n",
        "  list_images = []   # for the images passed through extractor function\n",
        "  tabular_list = []\n",
        "  list_proxies = []\n",
        "  list_review_diff = []\n",
        "  list_distilbart_name = []\n",
        "  list_joint_description = []\n",
        "  list_ids = []\n",
        "\n",
        "  for data in batch:\n",
        "\n",
        "    # indexing the image pixels form the dict\n",
        "    list_images.append(dict_images[str(data[62])])\n",
        "\n",
        "    list_ids.append(data[62]) # for saving the predictions\n",
        "\n",
        "    tabular_list.append(data[:62]) ## locations of tabular data\n",
        "    if int(data[65]) == 1:  ## location of categorical proxy variable\n",
        "      list_proxies.append([1,0,0])\n",
        "    elif int(data[65]) == 2:\n",
        "      list_proxies.append([0,1,0])\n",
        "    elif int(data[65]) == 3:\n",
        "      list_proxies.append([0,0,1])\n",
        "\n",
        "    list_review_diff.append(data[66])  ## location of cont. review diff variable\n",
        "\n",
        "    list_joint_description.append(dict_des[str(data[62])])\n",
        "\n",
        "    list_distilbart_name.append(dict_titles_llama_lora_2[str(data[62])])    # only change here!\n",
        "\n",
        "  list_images  = torch.tensor(list_images, dtype=torch.float32)\n",
        "  list_joint_description = torch.tensor(list_joint_description, dtype=torch.float32)\n",
        "  list_distilbart_name = torch.tensor(list_distilbart_name, dtype=torch.float32)\n",
        "  tabular_list = torch.tensor(tabular_list, dtype=torch.float32)\n",
        "  list_proxies = torch.tensor(list_proxies, dtype=torch.float32)\n",
        "\n",
        "  return list_images, list_distilbart_name, list_joint_description, tabular_list, list_proxies, list_review_diff, list_ids\n",
        "\n",
        "\n",
        "# images, names, des, tabular data, proxies, review_diff, ids\n"
      ],
      "metadata": {
        "id": "5YLDHfJqG00t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating counterfactuals for LLAMA (LoRa) generated titles"
      ],
      "metadata": {
        "id": "7h7qKpVBG00z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dl_counterfactuals_llama_lora_v2 = DataLoader(conterfac_dataset, collate_fn=collate_batch_counterfactual_llama_lora_v2, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "D0cJThjXG004"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ys, preds_, ids = get_counterfactuals(model_cont, dl_counterfactuals_llama_lora_v2, True)\n",
        "preds = [a[0] for a in preds_]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ff99e6e-7a1e-413f-da0f-c63921d6b653",
        "id": "uoEB1QR_G007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-cd1497a51829>:39: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:245.)\n",
            "  tabular_list = torch.tensor(tabular_list, dtype=torch.float32)\n",
            "<ipython-input-18-cd61884250f5>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  name = torch.tensor(batch[1]).to(device)\n",
            "<ipython-input-18-cd61884250f5>:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  joint_des = torch.tensor(batch[2]).to(device)\n",
            "<ipython-input-12-eb3a40074087>:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  encoded_des = torch.tensor(des_encoded)\n",
            "<ipython-input-12-eb3a40074087>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  encoded_name = torch.tensor(name_encoded)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cf_llama_lora_v2 = pd.DataFrame({\"id\": ids, \"pred\": preds, \"Y\": Ys})\n",
        "#cf_llama_lora.to_csv(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/cf_distilbart.csv\", index = False)"
      ],
      "metadata": {
        "id": "vdq1ISfXG00-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_preds_llama_lora_v2 = pd.merge(airbnb_london_filtered_images_imp_var_titles_with_llama_lora_v2[[\"id\", \"proxy\"]], cf_llama_lora_v2, how = \"left\", on = \"id\")\n"
      ],
      "metadata": {
        "id": "_SGUvaH_G01C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_preds_llama_lora_v2 = pd.merge(df_all_preds_llama_lora_v2, pred_disc_2_cont_real_name[[\"id\", \"pred\"]], on = \"id\", how = \"inner\")"
      ],
      "metadata": {
        "id": "-t2Ikj7lG01E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checking differences of preidcted review diff based on true titles and predicted review diff based on generated titles"
      ],
      "metadata": {
        "id": "_SKw_PBRG01G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###  ## x is is generated  tittle, y is true title\n",
        "\n",
        "\n",
        "np.mean(df_all_preds_llama_lora_v2[df_all_preds_llama_lora_v2.proxy != 3].pred_x - df_all_preds_llama_lora_v2[df_all_preds_llama_lora_v2.proxy != 3].pred_y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72ff34f9-0857-4eed-aa04-026621bd85db",
        "id": "GrGRb75qG01I"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.03048567114083427"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also checking result of permutation test based on proxy value"
      ],
      "metadata": {
        "id": "L_2FbFogG01K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "permutation_test(df_all_preds_llama_lora_v2[df_all_preds_llama_lora_v2.proxy != 3].pred_x, df_all_preds_llama_lora_v2[df_all_preds_llama_lora_v2.proxy != 3].pred_y, 1000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4b1dd4d-7bf7-45ce-cf03-650fc7c87df6",
        "id": "bOnCTfjXG01M"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.123"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LLama-Adapter"
      ],
      "metadata": {
        "id": "V5gP0PgrG01O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_titles_llama_adapter_v2 = pd.read_csv(\"/content/gdrive/My Drive/Thesis/loss_data/gen_titles_llama_adapter_v2.csv\")\n"
      ],
      "metadata": {
        "id": "jbDLR4uuG01Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# as I have fewer generated titles with LLaMa LLora\n",
        "airbnb_london_filtered_images_imp_var_titles_with_llama_adapter_v2 = pd.merge(airbnb_london_filtered_images_imp_var_titles,  gen_titles_llama_adapter_v2, how = \"inner\", on = \"id\")\n",
        "conterfac_dataset  = Simple_Dataset(airbnb_london_filtered_images_imp_var_titles_with_llama_adapter_v2)\n"
      ],
      "metadata": {
        "id": "l_7VBHviG01S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch_counterfactual_llama_adapter_v2(batch):\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  Idx_model refers to the location of the genrated names for a specific model\n",
        "  \"\"\"\n",
        "\n",
        "  list_images = []   # for the images passed through extractor function\n",
        "  tabular_list = []\n",
        "  list_proxies = []\n",
        "  list_review_diff = []\n",
        "  list_llama_adapter_name = []\n",
        "  list_joint_description = []\n",
        "  list_ids = []\n",
        "\n",
        "  for data in batch:\n",
        "\n",
        "    # indexing the image pixels form the dict\n",
        "    list_images.append(dict_images[str(data[62])])\n",
        "\n",
        "    list_ids.append(data[62]) # for saving the predictions\n",
        "\n",
        "    tabular_list.append(data[:62]) ## locations of tabular data\n",
        "    if int(data[65]) == 1:  ## location of categorical proxy variable\n",
        "      list_proxies.append([1,0,0])\n",
        "    elif int(data[65]) == 2:\n",
        "      list_proxies.append([0,1,0])\n",
        "    elif int(data[65]) == 3:\n",
        "      list_proxies.append([0,0,1])\n",
        "\n",
        "    list_review_diff.append(data[66])  ## location of cont. review diff variable\n",
        "\n",
        "    list_joint_description.append(dict_des[str(data[62])])\n",
        "\n",
        "    list_llama_adapter_name.append(dict_titles_llama_adapter_2[str(data[62])])    # only change here!\n",
        "\n",
        "  list_images  = torch.tensor(list_images, dtype=torch.float32)\n",
        "  list_joint_description = torch.tensor(list_joint_description, dtype=torch.float32)\n",
        "  list_llama_adapter_name = torch.tensor(list_llama_adapter_name, dtype=torch.float32)\n",
        "  tabular_list = torch.tensor(tabular_list, dtype=torch.float32)\n",
        "  list_proxies = torch.tensor(list_proxies, dtype=torch.float32)\n",
        "\n",
        "  return list_images, list_llama_adapter_name, list_joint_description, tabular_list, list_proxies, list_review_diff, list_ids\n",
        "\n",
        "\n",
        "# images, names, des, tabular data, proxies, review_diff, ids\n"
      ],
      "metadata": {
        "id": "1Esc5z8UG01U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Calculating counterfactuals for LLAMA-Adapter generated titles\n"
      ],
      "metadata": {
        "id": "rDYD_HSHG01W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dl_counterfactuals_llama_adapter_v2 = DataLoader(conterfac_dataset, collate_fn=collate_batch_counterfactual_llama_adapter_v2, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "0v19G2ztG01X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ys, preds_, ids = get_counterfactuals(model_cont, dl_counterfactuals_llama_adapter_v2, True)\n",
        "preds = [a[0] for a in preds_]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc6b5ee8-7559-45c1-8eef-3e6d68cfee74",
        "id": "S1DbFRvFG01Y"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-cd61884250f5>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  name = torch.tensor(batch[1]).to(device)\n",
            "<ipython-input-18-cd61884250f5>:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  joint_des = torch.tensor(batch[2]).to(device)\n",
            "<ipython-input-12-eb3a40074087>:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  encoded_des = torch.tensor(des_encoded)\n",
            "<ipython-input-12-eb3a40074087>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  encoded_name = torch.tensor(name_encoded)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cf_llama_adapter_v2 = pd.DataFrame({\"id\": ids, \"pred\": preds, \"Y\": Ys})\n"
      ],
      "metadata": {
        "id": "6KEHny1lG01a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "B50I-oCdNrbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_preds_llama_adapter_v2 = pd.merge(airbnb_london_filtered_images_imp_var_titles_with_llama_adapter_v2[[\"id\", \"proxy\"]], cf_llama_adapter_v2, how = \"left\", on = \"id\")\n"
      ],
      "metadata": {
        "id": "vX7pu3ImG01b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_preds_llama_adapter_v2 = pd.merge(df_all_preds_llama_adapter_v2, pred_disc_2_cont_real_name[[\"id\", \"pred\"]], on = \"id\", how = \"inner\")"
      ],
      "metadata": {
        "id": "jj-13VnLG01d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checking differences of preidcted review diff based on true titles and predicted review diff based on generated titles"
      ],
      "metadata": {
        "id": "Bk_nNYTFG01f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###  ## x is is generated  tittle, y is true title\n",
        "\n",
        "np.mean(df_all_preds_llama_adapter_v2[df_all_preds_llama_adapter_v2.proxy != 3].pred_x - df_all_preds_llama_adapter_v2[df_all_preds_llama_adapter_v2.proxy != 3].pred_y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63685dd8-51c9-4fbe-872b-825aa07c206a",
        "id": "Cf2F_L87G01g"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.027554424955467793"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "permutation_test(df_all_preds_llama_adapter_v2[df_all_preds_llama_adapter_v2.proxy != 3].pred_x, df_all_preds_llama_adapter_v2[df_all_preds_llama_adapter_v2.proxy != 3].pred_y, 1000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b959d4f5-34c7-4153-eeb8-8b95b30140c8",
        "id": "kctP6qSDG01i"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.182"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LLama (no PEFT)"
      ],
      "metadata": {
        "id": "YWpFajh0G01j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gen_titles_llama_no_peft_v2 = pd.read_csv(\"/content/gdrive/My Drive/Thesis/loss_data/gen_titles_llama_no_peft_v2.csv\")\n",
        "\n"
      ],
      "metadata": {
        "id": "zvJct_3GG01k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# as I have fewer generated titles with LLaMa LLora\n",
        "airbnb_london_filtered_images_imp_var_titles_with_llama_no_peft_v2 = pd.merge(airbnb_london_filtered_images_imp_var_titles,  gen_titles_llama_no_peft_v2, how = \"inner\", on = \"id\")\n",
        "conterfac_dataset  = Simple_Dataset(airbnb_london_filtered_images_imp_var_titles_with_llama_no_peft_v2)\n"
      ],
      "metadata": {
        "id": "sZnYEHhnG01m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch_counterfactual_llama_no_peft_v2(batch):\n",
        "\n",
        "\n",
        "  \"\"\"\n",
        "  Idx_model refers to the location of the genrated names for a specific model\n",
        "  \"\"\"\n",
        "\n",
        "  list_images = []   # for the images passed through extractor function\n",
        "  tabular_list = []\n",
        "  list_proxies = []\n",
        "  list_review_diff = []\n",
        "  list_llama_adapter_name = []\n",
        "  list_joint_description = []\n",
        "  list_ids = []\n",
        "\n",
        "  for data in batch:\n",
        "\n",
        "    # indexing the image pixels form the dict\n",
        "    list_images.append(dict_images[str(data[62])])\n",
        "\n",
        "    list_ids.append(data[62]) # for saving the predictions\n",
        "\n",
        "    tabular_list.append(data[:62]) ## locations of tabular data\n",
        "    if int(data[65]) == 1:  ## location of categorical proxy variable\n",
        "      list_proxies.append([1,0,0])\n",
        "    elif int(data[65]) == 2:\n",
        "      list_proxies.append([0,1,0])\n",
        "    elif int(data[65]) == 3:\n",
        "      list_proxies.append([0,0,1])\n",
        "\n",
        "    list_review_diff.append(data[66])  ## location of cont. review diff variable\n",
        "\n",
        "    list_joint_description.append(dict_des[str(data[62])])\n",
        "\n",
        "    list_llama_adapter_name.append(dict_titles_llama_no_peft_2[str(data[62])])    # only change here!\n",
        "\n",
        "  list_images  = torch.tensor(list_images, dtype=torch.float32)\n",
        "  list_joint_description = torch.tensor(list_joint_description, dtype=torch.float32)\n",
        "  list_llama_adapter_name = torch.tensor(list_llama_adapter_name, dtype=torch.float32)\n",
        "  tabular_list = torch.tensor(tabular_list, dtype=torch.float32)\n",
        "  list_proxies = torch.tensor(list_proxies, dtype=torch.float32)\n",
        "\n",
        "  return list_images, list_llama_adapter_name, list_joint_description, tabular_list, list_proxies, list_review_diff, list_ids\n",
        "\n",
        "\n",
        "# images, names, des, tabular data, proxies, review_diff, ids\n"
      ],
      "metadata": {
        "id": "af3DXNmMG01n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating counterfactuals for LLAMA generated titles (no peft)"
      ],
      "metadata": {
        "id": "7CYtOuYTG01p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dl_counterfactuals_llama_no_peft_v2 = DataLoader(conterfac_dataset, collate_fn=collate_batch_counterfactual_llama_no_peft_v2, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "eET6SJC4G01r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Ys, preds_, ids = get_counterfactuals(model_cont, dl_counterfactuals_llama_no_peft_v2, True)\n",
        "preds = [a[0] for a in preds_]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "153a71a0-7a94-40d6-913c-2a252aa47578",
        "id": "d4HCgnoUG01t"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-cd61884250f5>:55: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  name = torch.tensor(batch[1]).to(device)\n",
            "<ipython-input-18-cd61884250f5>:56: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  joint_des = torch.tensor(batch[2]).to(device)\n",
            "<ipython-input-12-eb3a40074087>:73: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  encoded_des = torch.tensor(des_encoded)\n",
            "<ipython-input-12-eb3a40074087>:82: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  encoded_name = torch.tensor(name_encoded)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cf_llama_no_peft_v2 = pd.DataFrame({\"id\": ids, \"pred\": preds, \"Y\": Ys})\n"
      ],
      "metadata": {
        "id": "db9soWZEG01u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_preds_llama_no_peft_v2 = pd.merge(airbnb_london_filtered_images_imp_var_titles_with_llama_no_peft_v2[[\"id\", \"proxy\"]], cf_llama_no_peft_v2, how = \"left\", on = \"id\")\n"
      ],
      "metadata": {
        "id": "bkpDOUIkG01x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all_preds_llama_no_peft_v2 = pd.merge(df_all_preds_llama_no_peft_v2, pred_disc_2_cont_real_name[[\"id\", \"pred\"]], on = \"id\", how = \"inner\")"
      ],
      "metadata": {
        "id": "dFERV8TUG01y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checking differences of preidcted review diff based on true titles and predicted review diff based on generated titles"
      ],
      "metadata": {
        "id": "N2yVsUlEG01z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###  ## x is is generated  tittle, y is true title\n",
        "\n",
        "np.mean(df_all_preds_llama_no_peft_v2[df_all_preds_llama_no_peft_v2.proxy != 3].pred_x - df_all_preds_llama_no_peft_v2[df_all_preds_llama_no_peft_v2.proxy != 3].pred_y)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d071fbda-f9a0-485d-d0ab-e8a8d70267cc",
        "id": "X0bo7r0fG011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.010117032491044224"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "permutation_test(df_all_preds_llama_no_peft_v2[df_all_preds_llama_no_peft_v2.proxy != 3].pred_x, df_all_preds_llama_no_peft_v2[df_all_preds_llama_no_peft_v2.proxy != 3].pred_y, 1000)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b435ad00-5ec0-4dbb-fe1c-a15951d516d9",
        "id": "EYk_aF4QG012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.603"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Joining counterfactuals and titles"
      ],
      "metadata": {
        "id": "GGiLHsl6Af5S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# renaming\n",
        "\n",
        "df_all_preds_distilbart = df_all_preds_distilbart.rename(columns={'pred':'pred_distilbart'})\n",
        "df_all_preds_peg = df_all_preds_peg.rename(columns={'pred':'pred_pegasus'})\n",
        "df_all_preds_bart = df_all_preds_bart.rename(columns={'pred':'pred_bart'})\n",
        "\n",
        "df_all_preds_llama_lora_v2 = df_all_preds_llama_lora_v2.rename(columns={'pred_x':'pred_llama_lora_v2'})\n",
        "df_all_preds_llama_adapter_v2 = df_all_preds_llama_adapter_v2.rename(columns={'pred_x':'pred_llama_adapter_v2'})\n",
        "df_all_preds_llama_no_peft_v2 = df_all_preds_llama_no_peft_v2.rename(columns={'pred_x':'pred_llama_no_peft_v2'})\n",
        "\n",
        "df_all_preds_llama_lora = df_all_preds_llama_lora.rename(columns={'pred_x':'pred_llama_lora'})\n",
        "df_all_preds_llama_adapter = df_all_preds_llama_adapter.rename(columns={'pred_x':'pred_llama_adapter'})\n",
        "df_all_preds_llama_no_peft = df_all_preds_llama_no_peft.rename(columns={'pred_x':'pred_llama_no_peft'})\n",
        "\n",
        "gen_titles_llama_lora_v2 = gen_titles_llama_lora_v2.rename(columns={'gen_title':'gen_title_llama_lora_v2'})\n",
        "gen_titles_llama_adapter_v2 = gen_titles_llama_adapter_v2.rename(columns={'gen_titles':'gen_titles_llama_adapter_v2'})\n",
        "gen_titles_llama_no_peft_v2 = gen_titles_llama_no_peft_v2.rename(columns={'gen_title':'gen_titles_llama_no_peft_v2'})\n",
        "\n",
        "\n",
        "gen_titles_llama_lora = gen_titles_llama_lora.rename(columns={'gen_title':'gen_title_llama_lora'})\n",
        "gen_titles_llama_adapter = gen_titles_llama_adapter.rename(columns={'gen_titles':'gen_titles_llama_adapter'})\n",
        "gen_titles_llama_no_peft = gen_titles_llama_no_peft.rename(columns={'gen_title':'gen_titles_llama_no_peft'})\n"
      ],
      "metadata": {
        "id": "4YBbR4vgD4xV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## merging couterfactual predictions\n",
        "\n",
        "merge_prep = pd.merge(df_all_preds_distilbart[[\"id\", \"pred_distilbart\", \"proxy\"]], df_all_preds_peg[[\"id\", \"pred_pegasus\"]], how = \"inner\", on  = \"id\")\n",
        "merge_prep = pd.merge(merge_prep,df_all_preds_bart[[\"id\", \"pred_bart\"]], how = \"inner\", on  = \"id\")\n",
        "\n",
        "\n",
        "merge_prep = pd.merge(merge_prep, df_all_preds_llama_lora[[\"id\", \"pred_llama_lora\"]], how = \"inner\", on  = \"id\")\n",
        "merge_prep = pd.merge(merge_prep, df_all_preds_llama_adapter[[\"id\", \"pred_llama_adapter\"]], how = \"inner\", on  = \"id\")\n",
        "merge_prep = pd.merge(merge_prep, df_all_preds_llama_no_peft[[\"id\", \"pred_llama_no_peft\"]], how = \"inner\", on  = \"id\")\n",
        "\n",
        "merge_prep = pd.merge(merge_prep, df_all_preds_llama_lora_v2[[\"id\", \"pred_llama_lora_v2\"]], how = \"inner\", on  = \"id\")\n",
        "merge_prep = pd.merge(merge_prep, df_all_preds_llama_adapter_v2[[\"id\", \"pred_llama_adapter_v2\"]], how = \"inner\", on  = \"id\")\n",
        "merge_prep = pd.merge(merge_prep, df_all_preds_llama_no_peft_v2[[\"id\", \"pred_llama_no_peft_v2\"]], how = \"inner\", on  = \"id\")\n",
        "\n",
        "merge_prep = pd.merge(merge_prep, airbnb_london_filtered_images_imp_var[[\"id\", \"name\"]], how = \"inner\", on  = \"id\")\n",
        "\n",
        "## merging together with generated titles using summarization methods\n",
        "merge_prep = pd.merge(merge_prep, gen_titles_summ_models[['id','gen_titles_distilbart', 'gen_titles_bart', 'gen_titles_pegasus']], how = \"inner\", on  = \"id\")\n",
        "\n",
        "## merging together with llama geenerated titles\n",
        "merge_prep = pd.merge(merge_prep, gen_titles_llama_lora[[\"id\", \"gen_title_llama_lora\"]], how = \"inner\", on  = \"id\")\n",
        "merge_prep = pd.merge(merge_prep, gen_titles_llama_no_peft[[\"id\", \"gen_titles_llama_no_peft\"]], how = \"inner\", on  = \"id\")\n",
        "merge_prep = pd.merge(merge_prep, gen_titles_llama_adapter[[\"id\", \"gen_titles_llama_adapter\"]], how = \"inner\", on  = \"id\")\n",
        "\n",
        "merge_prep = pd.merge(merge_prep, gen_titles_llama_lora_v2[[\"id\", \"gen_title_llama_lora_v2\"]], how = \"inner\", on  = \"id\")\n",
        "merge_prep = pd.merge(merge_prep, gen_titles_llama_no_peft_v2[[\"id\", \"gen_titles_llama_no_peft_v2\"]], how = \"inner\", on  = \"id\")\n",
        "\n",
        "\n",
        "merged_counterfactuals_titles = pd.merge(merge_prep, gen_titles_llama_adapter_v2[[\"id\", \"gen_titles_llama_adapter_v2\"]], how = \"inner\", on  = \"id\")\n"
      ],
      "metadata": {
        "id": "Uu2v3f6BAi0o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving to csv\n",
        "merged_counterfactuals_titles.to_csv(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/merged_counterfactuals_titles.csv\", index = False)\n"
      ],
      "metadata": {
        "id": "xh8g0MRyDEUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Finally, printing examples to be added to the apppendix of the thesis:"
      ],
      "metadata": {
        "id": "UY9HLZWhxkSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "from IPython.display import HTML"
      ],
      "metadata": {
        "id": "K03pCS3231kn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "merged_counterfactuals_titles = pd.read_csv(\"/content/gdrive/My Drive/Thesis/Discriminator_Predictions/merged_counterfactuals_titles.csv\")\n",
        "airbnb_london_filtered_images_imp_var = pd.read_csv(\"/content/gdrive/My Drive/Thesis/London_Data/airbnb_london_filtered_images_counterfactual_prep.csv\")\n"
      ],
      "metadata": {
        "id": "FUw6LyOixpH0"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "merged_counterfactuals_titles_imp = merged_counterfactuals_titles[['id','name', 'gen_titles_distilbart', 'gen_titles_bart',\n",
        "       'gen_titles_pegasus', 'gen_titles_llama_lora',\n",
        "       'gen_titles_llama_adapter', 'gen_titles_llama_no_peft',\n",
        "       'gen_title_llama_lora_v2', 'gen_titles_llama_no_peft_v2',\n",
        "       'gen_titles_llama_adapter_v2']]\n",
        "\n",
        "data_examples = pd.merge(merged_counterfactuals_titles_imp, airbnb_london_filtered_images_imp_var[['id', 'joint_description']], on = \"id\", how = \"left\").sample(n=1, axis = 0, random_state = 101)\n"
      ],
      "metadata": {
        "id": "f6R90jJJyFfW"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas import DataFrame\n",
        "from IPython.display import HTML\n",
        "HTML(data_examples.to_html())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        },
        "id": "uhwcFpNH3dJ9",
        "outputId": "95ad0adc-0e90-445f-eb69-5882c0094c58"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>name</th>\n",
              "      <th>gen_titles_distilbart</th>\n",
              "      <th>gen_titles_bart</th>\n",
              "      <th>gen_titles_pegasus</th>\n",
              "      <th>gen_titles_llama_lora</th>\n",
              "      <th>gen_titles_llama_adapter</th>\n",
              "      <th>gen_titles_llama_no_peft</th>\n",
              "      <th>gen_title_llama_lora_v2</th>\n",
              "      <th>gen_titles_llama_no_peft_v2</th>\n",
              "      <th>gen_titles_llama_adapter_v2</th>\n",
              "      <th>joint_description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>951</th>\n",
              "      <td>10807880</td>\n",
              "      <td>Double bedroom in a cosy house with garden</td>\n",
              "      <td>Cosy double bedroom in peaceful house</td>\n",
              "      <td>Cosy double bedroom in a 2 bedroom house</td>\n",
              "      <td>Cosy and warm double bedroom</td>\n",
              "      <td>Cozy, warm and comfy double bedroom</td>\n",
              "      <td>Cosy double bedroom in a 2 bedroom house</td>\n",
              "      <td>Victoria Station Tranquil House</td>\n",
              "      <td>Peaceful and Tranquil Double Bedroom in Central London.</td>\n",
              "      <td>Victoria Station, Tranquil Area, Private Garden.</td>\n",
              "      <td>Cozy and Warm Double Bedroom in a Tranquil Area with Nature Reserve Nearby.</td>\n",
              "      <td>25 minute connection to Central London, Victoria station. Cosy and warm double bedroom. Two bedroom house located in a peaceful and tranquil area with nature reserve within 3 minute walk. Private garden, living room, 2 separate toilets and bathroom. We are social and like having chats, but if you don’t we don’t mind and leave you to relax. Guest access Access to garden as well. Other things to note We have a medium sized dog with us. But, he is friendly and calm. We also have a 2 year old boy. But, very sociable and playful. . Close to nature reserve woods and moated manor on one side. But on the other side the train station within 12 minutes walk and also a shopping centre from station another 4 minutes walk.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    }
  ]
}